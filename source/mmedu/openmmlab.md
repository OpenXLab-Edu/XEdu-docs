# 走向OpenMMLab

## OpenMMLab简介

当你打开这个页面，说明MMEdu已经入门，并期望使用更多的参数，训练出更好的模型。

MMEdu源自OpenMMLab。OpenMMLab（浦视）是上海人工智能实验室的计算机视觉算法开源体系 OpenMMLab是深度学习时代全球领域最全面、最具影响力的视觉算法开源项目，全球最大最全的开源计算机视觉算法库，为学术和产业界提供一个可跨方向、结构精良、易复现的统一算法工具库。

OpenMMLab 已经累计开源了超过 30 个算法库，涵盖分类、检测、分割、视频理解等众多研究领域，拥有超过 300 种算法、2,400 多个预训练模型。在 GitHub 上获得超过 72,000 个标星，同时吸引了超过 1,500 名社区开发者参与项目贡献，用户遍及超过 110 个国家和地区，覆盖全国全球顶尖高校、研究机构和企业。

MMEdu保留了OpenMMLab的各种参数，尤其是模型训练的所有常见参数。如果要训练出更加专业的模型，你需要先了解OpenMMLab。

OpenMMLab官方地址：[https://openmmlab.com/](https://openmmlab.com/)


## 训练参数详解

`train`函数支持很多参数，为了降低难度，MMEdu已经给绝大多数的参数设置了默认值。根据具体的情况修改参数，可能会得到更好的训练效果。下面来详细说明`train`函数的各个参数。

`epochs`：默认参数为`100`，用于指定训练的轮次，而在上述代码中我们设置为`10`。

`batch_size`：批大小，一次训练所选取的样本数，指每次训练在训练集中取batch_size个样本训练。默认参数为`None`，如为`None`则默认为对应网络配置文件中设置的`samples_per_gpu`的值，用于指定一次训练所选取的样本数。当训练集样本非常多时，直接将这些数据输入到神经网络的话会导致计算量非常大，容易因内存不足导致内核挂掉，因此可引入`batch_size`参数的设置。关于`batch_size`的取值范围，应该大于类别数，小于样本数，且由于GPU对2的幂次的`batch`可以发挥更佳的性能，因此设置成16、32、64、128…时往往要比设置为整10、整100的倍数时表现更优。

`validate`：布尔值，只能为`True`或者`False`，默认参数为`True`，在训练结束后，设定是否需要在验证集上进行评估，`True`则是需要进行评估。

`random_seed`：随机种子策略，默认为`0`即不使用，使用随机种子策略会减小模型算法结果的随机性。

`save_fold`：模型的保存路径，参数为`None`，默认保存路径为`./checkpoints/cls_model/`，如果不想模型保存在该目录下，可自己指定路径。

`distributed`：布尔值，表示是否在分布式环境中训练该模型，默认为`False`。

`device`：训练时所使用的设备，默认为`'cpu'`，如果电脑支持GPU，也可以将参数修改为`'cuda'`，使用GPU进行推理。

`metric`：验证指标，默认参数为`'accuracy'`，在进行模型评估时会计算分类准确率，数值越高说明模型性能越好，我们在运行完程序之后也会看到这个结果。

`save_best`：验证指标，默认参数为`'auto'`，在进行模型评估时会计算分类准确率，数值越高说明模型性能越好，运行完程序之后会将这个结果保存。

`optimizer`：进行迭代时的优化器，默认参数为`SGD`，`SGD`会在训练的过程中迭代计算mini-bath的梯度。

`lr`：学习率，默认参数为`1e-2`即`0.01`，指定模型进行梯度下降时的步长。简单解释就是，学习率过小，训练过程会很缓慢，学习率过大时，模型精度会降低。

`checkpoint`：指定使用的模型权重文件，默认参数为`None`，如果没有指定模型权重文件，那么我们将会使用默认的模型权重文件进行推理。

执行上述代码之后的运行结果如下图：

![image](../images/mmedu/cls模型训练.png)

而在`checkpoints\cls_model`文件夹中我们会发现多了两种文件，一个是`***.log.json`文件，它记录了我们模型在训练过程中的一些参数，比如说学习率`lr`，所用时间`time`，以及损失`loss`等；另一个文件是.pth文件，这个是我们在训练过程中所保存的模型。

##  如果查看准确率

方式一：通过训练输出（如上图），运行训练代码时输出项里会出现学习率lr，所用时间time，以及损失loss，每一轮在验证上的accuracy_top-**等。

方式二：通过日志文件，在训练过程中我们会发现模型保存路径下（代码中指定指定）出现一个*.log.json文件，这就是日志文件，它记录了我们模型在训练过程中的一些信息。

当您启动验证集验证，即设置“validate=True”，表示每轮（每个epoch）训练后，在验证集（val_set）上测试一次准确率。那么每一轮训练结束时会呈现一次准确率，并且会生成best_accuracy_top-*.pth权重文件即最佳准确率权重文件。

accuracy_top-1：对一张图片，如果你的预测结果中概率最大的那个分类正确，则认为正确，再根据分类正确的样本数除以所有的样本数计算得到的准确率。

accuracy_top-5：对一张图片，如果预测概率前五名的答案中出现了正确答案，便认为正确，再根据分类正确的样本数除以所有的样本数计算得到的准确率，在MMClassification中，如果类别数量大于5会启动accuracy_top-5准确率。


## 日志文件解读

`Epoch[1][10/838]`: 1表示当前是第1个epoch，而10/838表示当前正在处理第10个批次，一共有838个批次。在深度学习模型的训练过程中，通常会将训练数据集分成若干个批次，每个批次包含一定数量的样本（每批次样本数和batch_size设置相关），训练时会使用这些批次逐步迭代来更新模型的参数。

`lr`: 学习率。

`eta`: 表示预计完成整个训练所需要的时间。

`time`: 表示本批次训练需要的时间。

`data_time`: 数据预处理的时间。

`memory`: 训练时占据内存或现存的大小。

`loss`: 本批次模型在训练集上计算的损失值。loss是衡量模型在训练集上预测结果与真实结果之间差异的指标。不同类型的模型（如分类、回归、生成等）使用不同的loss函数来优化模型，MMEdu的图像分类模型一般使用交叉熵损失函数。通常情况下，训练过程中的loss会逐渐下降，表示模型在逐步学习优化。


