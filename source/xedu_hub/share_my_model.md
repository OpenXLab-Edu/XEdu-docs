# 生态共建：分享我的模型方案
相信你已经领略到XEduHub的统一代码格式带来的便利了。但是如果我们有自己发现的好玩的模型，能不能也运行在XEduHub之上呢？答案是“必须可以”！

你可以在[魔搭社区](https://modelscope.cn/home)等平台上按照格式上传模型，然后只需要向好友分享这个名称即可在XEduHub工具中载入模型和相应的处理流程。

但是这样只有知道这个名称的好友能用到这个模型，为了让更多人知道你贡献的好玩的模型，我们诚邀您在上传模型之后，在这里填写[问卷](https://aicarrier.feishu.cn/share/base/form/shrcnZqkQ3n3EVkE9vEMhkMYAsf)登记您的模型，这样，就可以让您的模型加入[生态共建模型仓库](https://aicarrier.feishu.cn/wiki/VdWkwyNvtiUyAlkrOkEcZgBznOb?from=from_copylink)，让更多人看到并用上您的模型！

## 体验好友的模型
我们的生态伙伴上传了一个模型到[魔搭社区](https://modelscope.cn/models/fhl123/mobileone_test)，那么我们就可以使用这个模型啦！模型仓库名称为`fhl123/mobileone_test`，这个名称作为`repo`的值传入，创建一个模型，然后输入的数据为图片路径，最后我们就可以看到结果输出啦！
```python
from XEdu.hub import Workflow as wf
model = wf(repo='yikshing/emotion_ferplus')
res = model.inference('./Lenna_400x400.jpg')
print(res)
```
### 原理分析
为什么填写`repo`就可以了呢？这是因为仓库里存放了模型和模型数据前后处理函数。模型文件为onnx后缀，前后处理函数则定义在`data_process.py`文件中。

## 分享我的模型
现在我们已经感受到了开源共享模型的乐趣，那么如何分享我自己的模型呢？就跟随继续往下看吧！

### 第一步：本地模型仓库

#### 获取模型
网络上有很多好玩的onnx模型，但是要想把这个模型跑通，还是需要额外写很多代码，这样的模型让很多人打起了退堂鼓。如果我已经调通了这样的一个模型，把这样的处理流程分享出来，何乐而不为呢？

这里以onnx官方提供的情绪分类模型为例，我们下载这个模型，并为它编写前后处理代码，让模型能够在本地跑通。
- 模型下载地址：[emotion-ferplus-8.onnx](https://github.com/onnx/models/blob/main/validated/vision/body_analysis/emotion_ferplus/model/emotion-ferplus-8.onnx)
- 模型前后处理参考资料：[README.md](https://github.com/onnx/models/tree/main/validated/vision/body_analysis/emotion_ferplus)

假设我们把模型存储在`D:\my_model` ，我们需要把文件名重命名为`model.onnx` ，然后，在同级目录下再创建一个`data_process.py` 的文件，XEduHub会调用这个文件中编写的函数来运行模型。

参考模型资料，原始的前后处理如下：
```python
import numpy as np
from PIL import Image

def preprocess(image_path):
  input_shape = (1, 1, 64, 64)
  img = Image.open(image_path)
  img = img.resize((64, 64), Image.ANTIALIAS)
  img_data = np.array(img)
  img_data = np.resize(img_data, input_shape)
  return img_data

def softmax(scores):
  # your softmax function
  return scores

def postprocess(scores):
  '''
  This function takes the scores generated by the network and returns the class IDs in decreasing
  order of probability.
  '''
  prob = softmax(scores)
  prob = np.squeeze(prob)
  classes = np.argsort(prob)[::-1]
  return classes
```
我们将这段代码保存到`data_process.py` ，然后编写下面的测试代码，测试模型是否能够调通。
```python
from XEdu.hub import Workflow as wf
model = wf(repo='D:/my_model') # 注意这里的路径要使用绝对路径
res = model.inference('./Lenna_400x400.jpg')
print(res)
```
这里运行报错为`onnxruntime.capi.onnxruntime_pybind11_state.InvalidArgument: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Unexpected input data type. Actual: (tensor(uint8)) , expected: (tensor(float))` ，为此我们需要在前处理中添加一行`img_data = img_data.astype(np.float32)` 。经过这样的修改之后，我还是不太满意，因为输出的结果不太好理解，我这里想要为此添加一下中文类别名称的返回。最终的处理代码如下：
```python
import numpy as np
from PIL import Image

class_names = ['neutral中性', 'happiness高兴', 'surprise惊喜', 'sadness悲伤', 'anger气愤', 'disgust恶心', 'fear害怕', 'contempt蔑视']
def preprocess(image_path):
  input_shape = (1, 1, 64, 64)
  img = Image.open(image_path)
  img = img.resize((64, 64), Image.ANTIALIAS)
  img_data = np.array(img)
  img_data = np.resize(img_data, input_shape)
  img_data = img_data.astype(np.float32)
  return img_data

def softmax(scores):
  scores = np.exp(scores) / np.sum(np.exp(scores))
  return scores

def postprocess(scores):
  prob = softmax(scores)
  prob = np.squeeze(prob)
  classes = np.argsort(prob)[::-1]
  for i,c in enumerate(classes):
    print(class_names[c],prob[i])
  return prob,class_names[0]
```
我们再运行测试代码，输出结果如下：
```
neutral中性 0.55995744
happiness高兴 0.36672002
sadness悲伤 0.008014753
surprise惊喜 0.057720426
anger气愤 0.0036019378
contempt蔑视 0.0005505706
fear害怕 0.001121171
disgust恶心 0.0023137312
(array([5.5995744e-01, 3.6672002e-01, 8.0147535e-03, 5.7720426e-02,
       3.6019378e-03, 5.5057061e-04, 1.1211711e-03, 2.3137312e-03],
      dtype=float32), 'neutral中性')
```
这里，我们要说明一下，`data_process.py` 的要求，我们可选的函数有`preprocess` `postprocess` `inference` 三个，如果存在`inference` 则不调用XEduHub的默认onnx推理，而是替换为用户对inference的定义。`preprocess` 会在执行`inference` 之前执行，`postprocess` 会在执行`inference` 之后执行。

### 第二步：上传模型仓库

这里以[魔搭社区](https://modelscope.cn/home)为例，首先需要通过网页注册/登录，然后点击[创建模型](https://modelscope.cn/models/create)，填写相关信息，其中`是否公开`选择“`公开模型`”。点击创建后再上传其他文件。

点击“模型文件”，点击“添加文件”，然后上传模型文件，文件名为`model.onnx`（上传位置选择“根目录”，且需要填写“文件信息”）。

点击“添加文件”，继续添加文件，上传刚才的`data_process.py` 文件。

### 第三步：测试模型
接下来，我们测试一个模型是否可以顺利运行。下面代码中的`XXXXXXXXXX`替换为你的仓库名称。
![](../images/xeduhub/repo.png)
仓库名称可以点击箭头指向的复制按钮来获取。
```python
from XEdu.hub import Workflow as wf
model = wf(repo='XXXXXXXXXX')
res = model.inference('./Lenna_400x400.jpg')
print(res)
```
看起来运行一切正常，那么就ok啦！如果有问题的话，我们就需要调整一下代码，确保可以运行后，再分享出来。

运行代码之后，模型会自动下载到这段代码同级目录。

### 填写生态共建问卷登记模型
为了让更多人知道你贡献的好玩的模型，我们诚邀您在上传模型之后，在这里填写[问卷](https://aicarrier.feishu.cn/share/base/form/shrcnZqkQ3n3EVkE9vEMhkMYAsf)登记您的模型，这样，就可以让您的模型加入[生态共建模型仓库](https://aicarrier.feishu.cn/wiki/VdWkwyNvtiUyAlkrOkEcZgBznOb?from=from_copylink)，让更多人看到并用上您的模型！

