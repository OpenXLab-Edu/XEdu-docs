# 深度学习训练参数详解

## 参数

参数是刻画模型具体形状的一系列数值。打个比方，我们去商场买衣服，选择的款式就是深度学习中的“backbone”，而具体的尺码要根据你的具体情况而定，这就是参数。在深度学习的训练过程中，参数是自动形成的。参数训练的好，那么模型效果就好，参数训练不好，那么模型效果就差，就像买的衣服不合身一样。这里指的效果差包括“欠拟合”、“过拟合”等多种情况。

## 超参数

超参数其实才是我们平时习惯说的参数。在非深度学习的算法中，我们通常通过设置参数来刻画模型，而实际上，在深度学习中，参数是自动生成的，我们可以设置的，就是一些对训练策略的约束，这些设置，并不直接决定参数，因此我们常把它们称为“超参数”。

### 学习速率

学习速率（learning rate，lr）又称学习率、学习步长等。我们可以以看书做比喻，学习速率大，表示学习的粒度大，就好像读书只看标题和目录，能够把握大意，但并不精通，这样可以快速提升模型的准确率，但不够精细。学习速率小，表述学习的粒度小，就好像读书时咬文嚼字，能够学习的很精细，但用的时间也自然更长。

在深度学习任务中，我们通常认为问题求解应该在一个可接受的时间范围内，因此，时间/精度（准确率）的一个平衡就很关键，这就要靠学习速率来控制。

### 学习轮次

学习轮次（epoch）表示完成多少次训练，还是以看书做比喻，每一轮就好比看完一次书，模型会完整学习一次训练集，重复的轮数越多，一般效果越好。

### 优化器

优化器规定了学习的方向。我们以考试为例，要想考试成绩更高，可以有多种途径，这些途径就是可选的“优化器”，在不同的任务中，要根据实际情况来选择优化器。

常见的优化器是SGD和Adam。

### 训练策略

我们从读书和考试的角度去考虑，读书一般是先粗放地读，然后再仔细读。如果一种学习方式走不通，再换一种方式。

训练也是这样，一般先用大的学习率，再转为小的学习率继续训练。尝试使用多种优化器，经过不断尝试，让最终结果达到最优或可用的状态。