<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>MMEdu模块应用详解 &mdash; OpenXLabEdu  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="图像分类模块：MMClassification" href="mmclassification.html" />
    <link rel="prev" title="MMEdu安装和下载" href="installation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> OpenXLabEdu
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">目录</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../about.html">关于XEdu</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../mmedu.html">MMEdu入门</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="quick_start.html">MMEdu快速入门</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html">MMEdu安装和下载</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">MMEdu模块应用详解</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">1.MMEdu是什么？</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mmeduai">2.MMEdu和常见AI框架的比较</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#mmeduopencv">1）MMEdu和OpenCV的比较</a></li>
<li class="toctree-l4"><a class="reference internal" href="#mmedumediapipe">2）MMEdu和MediaPipe的比较</a></li>
<li class="toctree-l4"><a class="reference internal" href="#mmedukeras">3）MMEdu和Keras的比较</a></li>
<li class="toctree-l4"><a class="reference internal" href="#mmedufastai">4）MMEdu和FastAI的比较</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id2">3.模块概述</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id3">4.内置模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id4">5.数据集支持</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#imagenet">1.ImageNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="#coco">2.COCO</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id14">6.一键安装包目录详解</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id15">MMEdu目录：</a></li>
<li class="toctree-l4"><a class="reference internal" href="#checkpoints">checkpoints目录：</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dataset">dataset目录：</a></li>
<li class="toctree-l4"><a class="reference internal" href="#demo">demo目录：</a></li>
<li class="toctree-l4"><a class="reference internal" href="#howtostart">HowToStart目录：</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tools">tools目录：</a></li>
<li class="toctree-l4"><a class="reference internal" href="#visualization">visualization目录：</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="mmclassification.html">图像分类模块：MMClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="mmdetection.html">物体检测模块：MMDetection</a></li>
<li class="toctree-l2"><a class="reference internal" href="mmediting.html">图像处理模块：MMEditing</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../basenet.html">BaseNet入门</a></li>
<li class="toctree-l1"><a class="reference internal" href="../baseml.html">BaseML入门</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scitech_tools.html">相关科创工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="../support_resources.html">学习支持和资源获取</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dl_library.html">深度学习知识库</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">OpenXLabEdu</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../mmedu.html">MMEdu入门</a> &raquo;</li>
      <li>MMEdu模块应用详解</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/mmedu/introduction.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="mmedu">
<h1>MMEdu模块应用详解<a class="headerlink" href="#mmedu" title="Permalink to this heading"></a></h1>
<section id="id1">
<h2>1.MMEdu是什么？<a class="headerlink" href="#id1" title="Permalink to this heading"></a></h2>
<p>MMEdu源于国产人工智能视觉（CV）算法集成框架OpenMMLab，是一个“开箱即用”的深度学习开发工具。在继承OpenMMLab强大功能的同时，MMEdu简化了神经网络模型搭建和训练的参数，降低了编程的难度，并实现一键部署编程环境，让初学者通过简洁的代码完成各种SOTA模型（state-of-the-art，指在该项研究任务中目前最好/最先进的模型）的训练，并能够快速搭建出AI应用系统。</p>
<p>GitHub：<a class="reference external" href="https://github.com/OpenXLab-Edu/OpenMMLab-Edu">https://github.com/OpenXLab-Edu/OpenMMLab-Edu</a></p>
<p>国内镜像：<a class="reference external" href="https://gitee.com/openxlab-edu/OpenMMLab-Edu">https://gitee.com/openxlab-edu/OpenMMLab-Edu</a></p>
</section>
<section id="mmeduai">
<h2>2.MMEdu和常见AI框架的比较<a class="headerlink" href="#mmeduai" title="Permalink to this heading"></a></h2>
<section id="mmeduopencv">
<h3>1）MMEdu和OpenCV的比较<a class="headerlink" href="#mmeduopencv" title="Permalink to this heading"></a></h3>
<p>OpenCV是一个开源的计算机视觉框架，MMEdu的核心模块MMCV基于OpenCV，二者联系紧密。</p>
<p>OpenCV虽然是一个很常用的工具，但是普通用户很难在OpenCV的基础上训练自己的分类器。MMEdu则是一个入门门槛很低的深度学习开发工具，借助MMEdu和经典的网络模型，只要拥有一定数量的数据，连小学生都能训练出自己的个性化模型。</p>
</section>
<section id="mmedumediapipe">
<h3>2）MMEdu和MediaPipe的比较<a class="headerlink" href="#mmedumediapipe" title="Permalink to this heading"></a></h3>
<p>MediaPipe 是一款由 Google Research
开发并开源的多媒体机器学习模型应用框架，支持人脸识别、手势识别和表情识别等，功能非常强大。MMEdu中的MMPose模块关注的重点也是手势识别，功能类似。但MediaPipe是应用框架，而不是开发框架。换句话说，用MediaPipe只能完成其提供的AI识别功能，没办法训练自己的个性化模型。</p>
</section>
<section id="mmedukeras">
<h3>3）MMEdu和Keras的比较<a class="headerlink" href="#mmedukeras" title="Permalink to this heading"></a></h3>
<p>Keras是一个高层神经网络API，是对Tensorflow、Theano以及CNTK的进一步封装。OpenMMLab和Keras一样，都是为支持快速实验而生。MMEdu则源于OpenMMLab，其语法设计借鉴过Keras。</p>
<p>相当而言，MMEdu的语法比Keras更加简洁，对中小学生来说也更友好。目前MMEdu的底层框架是Pytorch，而Keras的底层是TensorFlow（虽然也有基于Pytorch的Keras）。</p>
</section>
<section id="mmedufastai">
<h3>4）MMEdu和FastAI的比较<a class="headerlink" href="#mmedufastai" title="Permalink to this heading"></a></h3>
<p>FastAI（Fast.ai）最受学生欢迎的MOOC课程平台，也是一个PyTorch的顶层框架。和OpenMMLab的做法一样，为了让新手快速实施深度学习，FastAI团队将知名的SOTA模型封装好供学习者使用。</p>
<p>FastAI同样基于Pytorch，但是和OpenMMLab不同的是，FastAI只能支持GPU。考虑到中小学的基础教育中很难拥有GPU环境，MMEdu特意将OpenMMLab中支持CPU训练的工具筛选出来，供中小学生使用。</p>
<p>MMEdu基于OpenMMLab的基础上开发，因为面向中小学，优先选择支持CPU训练的模块。</p>
</section>
</section>
<section id="id2">
<h2>3.模块概述<a class="headerlink" href="#id2" title="Permalink to this heading"></a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 42%" />
<col style="width: 16%" />
<col style="width: 42%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>模块名称</p></th>
<th class="head"><p>简称</p></th>
<th class="head"><p>功能</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>MMClassification</p></td>
<td><p>MMCLS</p></td>
<td><p>图片分类</p></td>
</tr>
<tr class="row-odd"><td><p>MMDetection</p></td>
<td><p>MMDET</p></td>
<td><p>图片中的物体检测</p></td>
</tr>
<tr class="row-even"><td><p>MMGeneration</p></td>
<td><p>MMGEN</p></td>
<td><p>GAN，风格化</p></td>
</tr>
<tr class="row-odd"><td><p>MMPose</p></td>
<td><p>MMPOSE</p></td>
<td><p>骨架</p></td>
</tr>
<tr class="row-even"><td><p>MMEditing</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>MMSegmentation</p></td>
<td></td>
<td><p>像素级识别</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id3">
<h2>4.内置模型<a class="headerlink" href="#id3" title="Permalink to this heading"></a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 24%" />
<col style="width: 53%" />
<col style="width: 24%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>模块名称</p></th>
<th class="head"><p>内置模型</p></th>
<th class="head"><p>功能</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>MMClassification</p></td>
<td><p>LeNet、ResNet18、ResNet50、MobileNet</p></td>
<td><p>图片分类</p></td>
</tr>
<tr class="row-odd"><td><p>MMDetection</p></td>
<td><p>FastRCNN</p></td>
<td><p>图片中的物体检测</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id4">
<h2>5.数据集支持<a class="headerlink" href="#id4" title="Permalink to this heading"></a></h2>
<p>MMEdu系列提供了包括分类、检测等任务的若干数据集，存储在dataset文件夹下。</p>
<section id="imagenet">
<h3>1.ImageNet<a class="headerlink" href="#imagenet" title="Permalink to this heading"></a></h3>
<p>ImageNet是斯坦福大学提出的一个用于视觉对象识别软件研究的大型可视化数据库，目前大部分模型的性能基准测试都在ImageNet上完成。MMEdu的MMClassification支持的数据集类型是ImageNet，如需训练自己创建的数据集，数据集需转换成ImageNet格式。</p>
<p>ImageNet格式数据集文件夹结构如下所示，图像数据文件夹和标签文件放在同级目录下。</p>
<div class="highlight-plain notranslate"><div class="highlight"><pre><span></span>imagenet
├── ...
├── training_set
│   ├── class_0
│   │   ├── filesname_0.JPEG
│   │   ├── filesname_1.JPEG
│   │   ├── ...
│   ├── ...
│   ├── class_n
│   │   ├── filesname_0.JPEG
│   │   ├── filesname_1.JPEG
│   │   ├── ...
├── classes.txt
├── ...
</pre></div>
</div>
<p>如上所示训练数据根据图片的类别，存放至不同子目录下，子目录名称为类别名称。</p>
<p>classes.txt包含数据集类别标签信息，每行包含一个类别名称，按照字母顺序排列。</p>
<div class="highlight-plain notranslate"><div class="highlight"><pre><span></span>class_0
class_1
...
class_n
</pre></div>
</div>
<p>为了验证和测试，我们建议划分训练集、验证集和测试集，此时需另外生成“val.txt”和“test.txt”这两个标签文件，要求是每一行都包含一个文件名和其相应的真实标签。格式如下所示：</p>
<div class="highlight-plain notranslate"><div class="highlight"><pre><span></span>filesname_0.jpg 0
filesname_1.jpg 0
...
filesname_a.jpg n
filesname_b.jpg n
</pre></div>
</div>
<p>注：真实标签的值应该位于<code class="docutils literal notranslate"><span class="pre">[0,类别数目-1]</span></code>之间。</p>
<p>这里，为您提供一段用Python代码完成标签文件的程序如下所示，程序中设计了“val.txt”和“test.txt”这两个标签文件每行会包含类别名称、文件名和真实标签。</p>
<div class="highlight-plain notranslate"><div class="highlight"><pre><span></span>import os
# 列出指定目录下的所有文件名，确定类别名称
classes = os.listdir(&#39;D:\测试数据集\EX_dataset\\training_set&#39;)
# 打开指定文件，并写入类别名称
with open(&#39;D:\测试数据集\EX_dataset/classes.txt&#39;,&#39;w&#39;) as f:
    for line in classes:
        str_line = line +&#39;\n&#39;
        f.write(str_line) # 文件写入str_line，即类别名称

test_dir = &#39;D:\测试数据集\EX_dataset\\test_set/&#39; # 指定测试集文件路径
# 打开指定文件，写入标签信息
with open(&#39;D:\测试数据集\EX_dataset/test.txt&#39;,&#39;w&#39;) as f:
    for cnt in range(len(classes)):
        t_dir = test_dir + classes[cnt]  # 指定测试集某个分类的文件目录
        files = os.listdir(t_dir) # 列出当前类别的文件目录下的所有文件名
        # print(files)
        for line in files:
            str_line = classes[cnt] + &#39;/&#39; + line + &#39; &#39;+str(cnt) +&#39;\n&#39;
            f.write(str_line)

val_dir = &#39;D:\测试数据集\EX_dataset\\val_set/&#39;  # 指定文件路径
# 打开指定文件，写入标签信息
with open(&#39;D:\测试数据集\EX_dataset/val.txt&#39;, &#39;w&#39;) as f:
    for cnt in range(len(classes)):
        t_dir = val_dir + classes[cnt]  # 指定验证集某个分类的文件目录
        files = os.listdir(t_dir)  # 列出当前类别的文件目录下的所有文件名
        # print(files)
        for line in files:
            str_line = classes[cnt] + &#39;/&#39; + line + &#39; &#39; + str(cnt) + &#39;\n&#39;
            f.write(str_line)  # 文件写入str_line，即标注信息
</pre></div>
</div>
<p>至于如何从零开始制作一个ImageNet格式的数据集，可参考如下步骤。</p>
<section id="id5">
<h4>第一步：整理图片<a class="headerlink" href="#id5" title="Permalink to this heading"></a></h4>
<p>您可以用任何设备拍摄图像，也可以从视频中抽取帧图像，需要注意，这些图像可以被划分为多个类别。每个类别建立一个文件夹，文件夹名称为类别名称，将图片放在其中。</p>
<p>接下来需要对图片进行尺寸、保存格式等的统一，可使用如下代码：</p>
<div class="highlight-plain notranslate"><div class="highlight"><pre><span></span>from PIL import Image
from torchvision import transforms
import os

def makeDir(folder_path):
    if not os.path.exists(folder_path):  # 判断是否存在文件夹如果不存在则创建为文件夹
        os.makedirs(folder_path)

classes = os.listdir(&#39;D:\测试数据集\自定义数据集&#39;)
read_dir = &#39;D:\测试数据集\自定义数据集/&#39; # 指定原始图片路径
new_dir = &#39;D:\测试数据集\自定义数据集new/&#39;
for cnt in range(len(classes)):
    r_dir = read_dir + classes[cnt] + &#39;/&#39;
    files = os.listdir(r_dir)
    for index,file in enumerate(files):
        img_path = r_dir + file
        img = Image.open(img_path)   # 读取图片
        resize = transforms.Resize([224, 224])
        IMG = resize(img)
        w_dir = new_dir + classes[cnt] + &#39;/&#39;
        makeDir(w_dir)
        save_path = w_dir + str(index)+&#39;.jpg&#39;
        IMG = IMG.convert(&#39;RGB&#39;)
        IMG.save(save_path)
</pre></div>
</div>
</section>
<section id="id6">
<h4>第二步：划分训练集、验证集和测试集<a class="headerlink" href="#id6" title="Permalink to this heading"></a></h4>
<p>根据整理的数据集大小，按照一定比例拆分训练集、验证集和测试集，可使用如下代码将原始数据集按照“6:2:2”的比例拆分。</p>
<div class="highlight-plain notranslate"><div class="highlight"><pre><span></span>import os
import shutil
# 列出指定目录下的所有文件名，确定类别名称
classes = os.listdir(&#39;D:\测试数据集\自定义表情数据集&#39;)

# 定义创建目录的方法
def makeDir(folder_path):
    if not os.path.exists(folder_path):  # 判断是否存在文件夹如果不存在则创建为文件夹
        os.makedirs(folder_path)

# 指定文件目录
read_dir = &#39;D:\测试数据集\自定义表情数据集/&#39; # 指定原始图片路径
train_dir = &#39;D:\测试数据集\自制\EX_dataset\\training_set/&#39; # 指定训练集路径
test_dir = &#39;D:\测试数据集\自制\EX_dataset\\test_set/&#39; # 指定测试集路径
val_dir = &#39;D:\测试数据集\自制\EX_dataset\\val_set/&#39; # 指定验证集路径

for cnt in range(len(classes)):
    r_dir = read_dir + classes[cnt] + &#39;/&#39;  # 指定原始数据某个分类的文件目录
    files = os.listdir(r_dir)  # 列出某个分类的文件目录下的所有文件名
    files = files[:1000]
    # 按照6:2:2拆分文件名
    offset1 = int(len(files) * 0.6)
    offset2 = int(len(files) * 0.8)
    training_data = files[:offset1]
    val_data = files[offset1:offset2]
    test_data = files[offset2:]

    # 根据拆分好的文件名新建文件目录放入图片
    for index,fileName in enumerate(training_data):
        w_dir = train_dir + classes[cnt] + &#39;/&#39;  # 指定训练集某个分类的文件目录
        makeDir(w_dir)
        shutil.copy(r_dir + fileName,w_dir + classes[cnt] + str(index)+&#39;.jpg&#39;)
    for index,fileName in enumerate(test_data):
        w_dir = test_dir + classes[cnt] + &#39;/&#39;  # 指定测试集某个分类的文件目录
        makeDir(w_dir)
        shutil.copy(r_dir + fileName, w_dir + classes[cnt] + str(index) + &#39;.jpg&#39;)
    for index,fileName in enumerate(val_data):
        w_dir = val_dir + classes[cnt] + &#39;/&#39;  # 指定验证集某个分类的文件目录
        makeDir(w_dir)
        shutil.copy(r_dir + fileName, w_dir + classes[cnt] + str(index) + &#39;.jpg&#39;)
</pre></div>
</div>
</section>
<section id="id7">
<h4>第三步：生成标签文件<a class="headerlink" href="#id7" title="Permalink to this heading"></a></h4>
<p>划分完训练集、验证集和测试集，我们需要生成“classes.txt”，“val.txt”和“test.txt”，使用上文介绍的Python代码完成标签文件的程序生成标签文件。</p>
</section>
<section id="id8">
<h4>第四步：给数据集命名<a class="headerlink" href="#id8" title="Permalink to this heading"></a></h4>
<p>最后，我们将这些文件放在一个文件夹中，命名为数据集的名称。这样，在训练的时候，只要通过<code class="docutils literal notranslate"><span class="pre">model.load_dataset</span></code>指定数据集的路径就可以了。</p>
</section>
</section>
<section id="coco">
<h3>2.COCO<a class="headerlink" href="#coco" title="Permalink to this heading"></a></h3>
<p>COCO数据集是微软于2014年提出的一个大型的、丰富的检测、分割和字幕数据集，包含33万张图像，针对目标检测和实例分割提供了80个类别的物体的标注，一共标注了150万个物体。MMEdu的MMDetection支持的数据集类型是COCO，如需训练自己创建的数据集，数据集需转换成COCO格式。</p>
<p>MMEdu的MMDetection设计的COCO格式数据集文件夹结构如下所示，“annotations”文件夹存储标注文件，“images”文件夹存储用于训练、验证、测试的图片。</p>
<div class="highlight-plain notranslate"><div class="highlight"><pre><span></span>coco
├── annotations
│   ├── train.json
│   ├── ...
├── images
│   ├── train
│   │   ├── filesname_0.JPEG
│   │   ├── filesname_1.JPEG
│   │   ├── ...
│   ├── ...
</pre></div>
</div>
<p>如果您的文件夹结构和上方不同，则需要在“Detection_Edu.py”文件中修改<code class="docutils literal notranslate"><span class="pre">load_dataset</span></code>方法中的数据集和标签加载路径。</p>
<p>COCO数据集的标注信息存储在“annotations”文件夹中的<code class="docutils literal notranslate"><span class="pre">json</span></code>文件中，需满足COCO标注格式，基本数据结构如下所示。</p>
<div class="highlight-plain notranslate"><div class="highlight"><pre><span></span># 全局信息
{
    &quot;images&quot;: [image],
    &quot;annotations&quot;: [annotation],
    &quot;categories&quot;: [category]
}

# 图像信息标注，每个图像一个字典
image {
    &quot;id&quot;: int,  # 图像id编号，可从0开始
    &quot;width&quot;: int, # 图像的宽
    &quot;height&quot;: int,  # 图像的高
    &quot;file_name&quot;: str, # 文件名
}

# 检测框标注，图像中所有物体及边界框的标注，每个物体一个字典
annotation {
    &quot;id&quot;: int,  # 注释id编号
    &quot;image_id&quot;: int,  # 图像id编号
    &quot;category_id&quot;: int,   # 类别id编号
    &quot;segmentation&quot;: RLE or [polygon],  # 分割具体数据，用于实例分割
    &quot;area&quot;: float,  # 目标检测的区域大小
    &quot;bbox&quot;: [x,y,width,height],  # 目标检测框的坐标详细位置信息
    &quot;iscrowd&quot;: 0 or 1,  # 目标是否被遮盖，默认为0
}

# 类别标注
categories [{
    &quot;id&quot;: int, # 类别id编号
    &quot;name&quot;: str, # 类别名称
    &quot;supercategory&quot;: str, # 类别所属的大类，如哈巴狗和狐狸犬都属于犬科这个大类
}]
</pre></div>
</div>
<p>​ 这里，为您提供一种自己制作COCO格式数据集的方法。</p>
<section id="id9">
<span id="id10"></span><h4>第一步、整理图片<a class="headerlink" href="#id9" title="Permalink to this heading"></a></h4>
<p>根据需求按照自己喜欢的方式收集图片，图片中包含需要检测的信息即可，可以使用ImageNet格式数据集整理图片的方式对收集的图片进行预处理。</p>
</section>
<section id="id11">
<h4>第二步、标注图片<a class="headerlink" href="#id11" title="Permalink to this heading"></a></h4>
<p>可使用LabelMe批量打开图片文件夹的图片，进行标注并保存为json文件。</p>
<ul class="simple">
<li><p>LabelMe：格式为LabelMe，提供了转VOC、COCO格式的脚本，可以标注矩形、圆形、线段、点。标注语义分割、实例分割数据集尤其推荐。</p></li>
<li><p>LabelMe安装与打开方式：<code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">labelme</span></code>安装完成后输入<code class="docutils literal notranslate"><span class="pre">labelme</span></code>即可打开。</p></li>
</ul>
</section>
<section id="id12">
<h4>第三步、转换成COCO标注格式<a class="headerlink" href="#id12" title="Permalink to this heading"></a></h4>
<p>将LabelMe格式的标注文件转换成COCO标注格式，可以使用如下代码：</p>
<div class="highlight-plain notranslate"><div class="highlight"><pre><span></span>import json
import numpy as np
import glob
import PIL.Image
from PIL import ImageDraw
from shapely.geometry import Polygon

class labelme2coco(object):
    def __init__(self, labelme_json=[], save_json_path=&#39;./new.json&#39;):
        &#39;&#39;&#39;
        :param labelme_json: 所有labelme的json文件路径组成的列表
        :param save_json_path: json保存位置
        &#39;&#39;&#39;
        self.labelme_json = labelme_json
        self.save_json_path = save_json_path
        self.annotations = []
        self.images = []
        self.categories = [{&#39;supercategory&#39;: None, &#39;id&#39;: 1, &#39;name&#39;: &#39;cat&#39;},{&#39;supercategory&#39;: None, &#39;id&#39;: 2, &#39;name&#39;: &#39;dog&#39;}] # 指定标注的类别
        self.label = []
        self.annID = 1
        self.height = 0
        self.width = 0
        self.save_json()

    # 定义读取图像标注信息的方法
    def image(self, data, num):
        image = {}
        height = data[&#39;imageHeight&#39;]
        width = data[&#39;imageWidth&#39;]
        image[&#39;height&#39;] = height
        image[&#39;width&#39;] = width
        image[&#39;id&#39;] = num + 1
        image[&#39;file_name&#39;] = data[&#39;imagePath&#39;].split(&#39;/&#39;)[-1]
        self.height = height
        self.width = width
        return image

    # 定义数据转换方法
    def data_transfer(self):
        for num, json_file in enumerate(self.labelme_json):
            with open(json_file, &#39;r&#39;) as fp:
                data = json.load(fp)  # 加载json文件
                self.images.append(self.image(data, num)) # 读取所有图像标注信息并加入images数组
                for shapes in data[&#39;shapes&#39;]:
                    label = shapes[&#39;label&#39;]
                    points = shapes[&#39;points&#39;]
                    shape_type = shapes[&#39;shape_type&#39;]
                    if shape_type == &#39;rectangle&#39;:
                        points = [points[0],[points[0][0],points[1][1]],points[1],[points[1][0],points[0][1]]]
                    self.annotations.append(self.annotation(points, label, num)) # 读取所有检测框标注信息并加入annotations数组
                    self.annID += 1
        print(self.annotations)

    # 定义读取检测框标注信息的方法
    def annotation(self, points, label, num):
        annotation = {}
        annotation[&#39;segmentation&#39;] = [list(np.asarray(points).flatten())]
        poly = Polygon(points)
        area_ = round(poly.area, 6)
        annotation[&#39;area&#39;] = area_
        annotation[&#39;iscrowd&#39;] = 0
        annotation[&#39;image_id&#39;] = num + 1
        annotation[&#39;bbox&#39;] = list(map(float, self.getbbox(points)))
        annotation[&#39;category_id&#39;] = self.getcatid(label)
        annotation[&#39;id&#39;] = self.annID
        return annotation

    # 定义读取检测框的类别信息的方法
    def getcatid(self, label):
        for categorie in self.categories:
            if label == categorie[&#39;name&#39;]:
                return categorie[&#39;id&#39;]
        return -1

    def getbbox(self, points):
        polygons = points
        mask = self.polygons_to_mask([self.height, self.width], polygons)
        return self.mask2box(mask)

    def mask2box(self, mask):
        &#39;&#39;&#39;从mask反算出其边框
        mask：[h,w]  0、1组成的图片
        1对应对象，只需计算1对应的行列号（左上角行列号，右下角行列号，就可以算出其边框）
        &#39;&#39;&#39;
        # np.where(mask==1)
        index = np.argwhere(mask == 1)
        rows = index[:, 0]
        clos = index[:, 1]
        # 解析左上角行列号
        left_top_r = np.min(rows)  # y
        left_top_c = np.min(clos)  # x

        # 解析右下角行列号
        right_bottom_r = np.max(rows)
        right_bottom_c = np.max(clos)

        return [left_top_c, left_top_r, right_bottom_c - left_top_c,
                right_bottom_r - left_top_r]  # [x1,y1,w,h] 对应COCO的bbox格式

    def polygons_to_mask(self, img_shape, polygons):
        mask = np.zeros(img_shape, dtype=np.uint8)
        mask = PIL.Image.fromarray(mask)
        xy = list(map(tuple, polygons))
        PIL.ImageDraw.Draw(mask).polygon(xy=xy, outline=1, fill=1)
        mask = np.array(mask, dtype=bool)
        return mask

    def data2coco(self):
        data_coco = {}
        data_coco[&#39;images&#39;] = self.images
        data_coco[&#39;categories&#39;] = self.categories
        data_coco[&#39;annotations&#39;] = self.annotations
        return data_coco

    def save_json(self):
        self.data_transfer()
        self.data_coco = self.data2coco()
        # 保存json文件
        json.dump(self.data_coco, open(self.save_json_path, &#39;w&#39;), indent=4)  # 写入指定路径的json文件，indent=4 更加美观显示

labelme_json = glob.glob(&#39;picture/*.json&#39;)  # 获取指定目录下的json格式的文件
labelme2coco(labelme_json, &#39;picture/new.json&#39;) # 指定生成文件路径
</pre></div>
</div>
</section>
<section id="id13">
<h4>第四步、按照目录结构整理文件<a class="headerlink" href="#id13" title="Permalink to this heading"></a></h4>
<p>创建两个文件夹“images”和“annotations”，分别用于存放图片以及标注信息。按照要求的目录结构，整理好文件夹的文件，最后将文件夹重新命名，在训练的时候，只要通过<code class="docutils literal notranslate"><span class="pre">model.load_dataset</span></code>指定数据集的路径就可以了。</p>
</section>
</section>
</section>
<section id="id14">
<h2>6.一键安装包目录详解<a class="headerlink" href="#id14" title="Permalink to this heading"></a></h2>
<p>MMEdu一键安装版是一个压缩包，解压后即可使用。</p>
<p>MMEdu的根目录结构如下：</p>
<div class="highlight-plain notranslate"><div class="highlight"><pre><span></span>OpenMMLab-Edu
├── MMEdu
├── checkpoints
├── dataset
├── demo
├── HowToStart
├── tools（github)
├── visualization（github)
├── setup.bat
├── pyzo.exe
├── run_jupyter.bat
</pre></div>
</div>
<p>接下来对每层子目录进行介绍。</p>
<section id="id15">
<h3>MMEdu目录：<a class="headerlink" href="#id15" title="Permalink to this heading"></a></h3>
<p>存放各个模块的底层代码、算法模型文件夹“models”和封装环境文件夹“mmedu”。“models”文件夹中提供了各个模块常见的网络模型，内置模型配置文件和说明文档，说明文档提供了模型简介、特点、预训练模型下载链接和适用领域等。“mmedu”文件夹打包了MMEdu各模块运行所需的环境和中小学课程常用的库。</p>
</section>
<section id="checkpoints">
<h3>checkpoints目录：<a class="headerlink" href="#checkpoints" title="Permalink to this heading"></a></h3>
<p>存放各个模块的预训练模型的权重文件，分别放在以模块名称命名的文件夹下，如“cls_model”。</p>
</section>
<section id="dataset">
<h3>dataset目录：<a class="headerlink" href="#dataset" title="Permalink to this heading"></a></h3>
<p>存放为各个模块任务准备的数据集，分别放在以模块名称命名的文件夹下，如“cls”。同时github上此目录下还存放了各个模块自定义数据集的说明文档，如“pose-dataset.md”，文档提供了每个模块对应的数据集格式、下载链接、使用说明、自制数据集流程。</p>
</section>
<section id="demo">
<h3>demo目录：<a class="headerlink" href="#demo" title="Permalink to this heading"></a></h3>
<p>存放各个模块的测试程序，如“cls_demo.py”，并提供了测试图片。测试程序包括<code class="docutils literal notranslate"><span class="pre">py</span></code>文件和<code class="docutils literal notranslate"><span class="pre">ipynb</span></code>文件，可支持各种“Python
IDE”和“jupyter
notebook”运行，可运行根目录的“pyzo.exe”和“run_jupyter.bat”后打开测试程序。</p>
</section>
<section id="howtostart">
<h3>HowToStart目录：<a class="headerlink" href="#howtostart" title="Permalink to this heading"></a></h3>
<p>存放各个模块的使用教程文档，如“MMClassfication使用教程.md”，文档提供了代码详细说明、参数说明与使用等。同时github上此目录下还存放了OpenMMLab各个模块的开发文档供感兴趣的老师和同学参考，如“OpenMMLab_MMClassification.md”，提供了模块介绍、不同函数使用、深度魔改、添加网络等。</p>
</section>
<section id="tools">
<h3>tools目录：<a class="headerlink" href="#tools" title="Permalink to this heading"></a></h3>
<p>存放数据集格式的转换、不同框架的部署等通用工具。后续会陆续开发数据集查看工具、数据集标注工具等工具。</p>
</section>
<section id="visualization">
<h3>visualization目录：<a class="headerlink" href="#visualization" title="Permalink to this heading"></a></h3>
<p>存放可视化界面。</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="installation.html" class="btn btn-neutral float-left" title="MMEdu安装和下载" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mmclassification.html" class="btn btn-neutral float-right" title="图像分类模块：MMClassification" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021-2022 OpenXLabEdu.All Rights Reserved.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>