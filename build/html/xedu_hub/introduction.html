<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>XEduHub功能详解 &mdash; OpenXLabEdu  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=b3ba4146"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="计算机视觉库MMEdu" href="../mmedu.html" />
    <link rel="prev" title="XEduHub安装" href="installation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            OpenXLabEdu
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">目录</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../about.html">关于XEdu</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../xedu_hub.html">深度学习工具库XEduHub</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="quick_start.html">快速体验XEduHub</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html">XEduHub安装</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">XEduHub功能详解</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">XEduHub是什么？</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">XEduHub有多棒？</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id3">解锁XEduHub的使用方法</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id4">内置任务</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id5">方向一：关键点识别</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id15">方向二：目标检测</a></li>
<li class="toctree-l4"><a class="reference internal" href="#ocr">方向三：光学字符识别（OCR）</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id29">外置任务</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#mmedu">基于MMEdu导出模型推理</a></li>
<li class="toctree-l4"><a class="reference internal" href="#basenn">基于BaseNN导出模型推理</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id38">基于用户自定义模型推理</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#ai">多元AI模型综合应用</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id39">实时人体关键点识别</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id40"><strong>拓展：视频中的人体关键点识别</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id41">多人脸关键点识别</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id42">人脸检测控制舵机方向</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../mmedu.html">计算机视觉库MMEdu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basenn.html">神经网络库BaseNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../baseml.html">传统机器学习库BaseML</a></li>
<li class="toctree-l1"><a class="reference internal" href="../easydl.html">EasyDL系列无代码工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basedt.html">数据处理库BaseDT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basedeploy.html">模型部署库BaseDeploy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scitech_tools.html">相关科创工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="../support_resources.html">学习支持和资源获取</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dl_library.html">深度学习知识库</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">OpenXLabEdu</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../xedu_hub.html">深度学习工具库XEduHub</a></li>
      <li class="breadcrumb-item active">XEduHub功能详解</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/xedu_hub/introduction.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="xeduhub">
<h1>XEduHub功能详解<a class="headerlink" href="#xeduhub" title="Permalink to this heading"></a></h1>
<section id="id1">
<h2>XEduHub是什么？<a class="headerlink" href="#id1" title="Permalink to this heading"></a></h2>
<p>XEduHub是一个专为快速、便捷地利用最先进的深度学习模型完成任务而设计的工具库。其设计灵感源自PyTorchHub，旨在以工作流的方式，高效地完成深度学习任务。XEduHub的独特之处在于它内置了大量优质的深度学习SOTA模型，无需用户自行进行繁琐的模型训练。用户只需将这些现成的模型应用于特定任务，便能轻松进行AI应用实践。</p>
<p>想象一下，你的玩具箱里有很多玩具，每次想玩的时候，你只需要打开玩具箱，挑选你想要的玩具来玩。XEduHub就像是一个充满了AI玩具的箱子，里面有很多已经做好的AI模型，我们可以直接用它们来完成不同的任务。</p>
<p><img alt="../_images/eason.gif" src="../_images/eason.gif" /></p>
</section>
<section id="id2">
<h2>XEduHub有多棒？<a class="headerlink" href="#id2" title="Permalink to this heading"></a></h2>
<ul class="simple">
<li><p><strong>简单易用</strong>：就像玩玩具一样，不需要专业知识，只要按照指导，你就可以使用这些AI模型。</p></li>
<li><p><strong>无需训练</strong>：你不需要自己制作玩具，里面的AI模型都已经为你准备好了。</p></li>
<li><p><strong>节省时间</strong>：不需要等待，使用XEduHub，选取你需要的模型，然后就可以开始你的AI之旅。</p></li>
</ul>
</section>
<section id="id3">
<h2>解锁XEduHub的使用方法<a class="headerlink" href="#id3" title="Permalink to this heading"></a></h2>
<p>XEduHub作为一个深度学习工具库，集成了许多深度学习领域优质的SOTA模型，能够帮助用户在不进模型训练的前提下，用少量的代码，快速实现计算机视觉、自然语言处理等多个深度学习领域的任务。</p>
<p>一般使用步骤是：</p>
<p>步骤1：<a class="reference external" href="https://xedu.readthedocs.io/zh/master/xedu_hub/installation.html">安装</a>并导入XEduHub库</p>
<p>步骤2：选择你的AI玩具</p>
<p>步骤3：使用AI玩具</p>
<p>有了模型，你就可以使用它来完成你的任务啦！</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 步骤一：导入库</span>
<span class="kn">from</span> <span class="nn">XEdu.hub</span> <span class="kn">import</span> <span class="n">Workflow</span> <span class="k">as</span> <span class="n">wf</span>
<span class="c1"># 步骤二：选择你的AI玩具</span>
<span class="n">face</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;face&quot;</span><span class="p">)</span> <span class="c1"># 实例化模型</span>
<span class="c1"># 步骤三：使用你的AI玩具</span>
<span class="n">img</span> <span class="o">=</span> <span class="s1">&#39;face.jpg&#39;</span>
<span class="c1"># 进行推理，同时返回结果和带标注的图片</span>
<span class="n">result</span><span class="p">,</span><span class="n">new_img</span> <span class="o">=</span> <span class="n">face</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">img</span><span class="p">,</span><span class="n">img_type</span><span class="o">=</span><span class="s1">&#39;cv2&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="c1"># 输出推理结果</span>
<span class="n">face</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">new_img</span><span class="p">)</span> <span class="c1"># 显示带标注图片</span>
</pre></div>
</div>
<p>一旦你安装好XEduHub并导入到代码中后，你就可以查看里面所有的AI模型。看看哪一个是你想要的，然后选择它！下文会为你分任务解读。示例代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">XEdu.hub</span> <span class="kn">import</span> <span class="n">Workflow</span> <span class="k">as</span> <span class="n">wf</span>
<span class="c1"># 目前支持的任务</span>
<span class="n">wf</span><span class="o">.</span><span class="n">support_task</span><span class="p">()</span>
</pre></div>
</div>
<p><img alt="../_images/task.png" src="../_images/task.png" /></p>
</section>
<section id="id4">
<h2>内置任务<a class="headerlink" href="#id4" title="Permalink to this heading"></a></h2>
<p>XEduHub内置多个深度学习领域优质的SOTA模型，支持多种类型的内置任务。</p>
<section id="id5">
<h3>方向一：关键点识别<a class="headerlink" href="#id5" title="Permalink to this heading"></a></h3>
<p>关键点识别是深度学习中的一项关键任务，旨在检测图像或视频中的关键位置，通常代表物体或人体的重要部位。</p>
<section id="id6">
<h4>1. 模型声明<a class="headerlink" href="#id6" title="Permalink to this heading"></a></h4>
<p>在第一次声明模型时代码运行用时较长，是因为要将预训练模型从云端下载到本地中，从而便于用户进行使用。</p>
<p>你可以在当前项目中找到名为<strong>checkpoints</strong>的文件夹，里面保存的就是下载下来的预训练模型。当代码运行时，会先在本地的同级目录中寻找是否有已下载的预训练模型，如果没有，到本地缓存中寻找，如果本地缓存没有，查看是不是指定了模型的路径，如果都没有，到网络下载。</p>
</section>
<section id="id7">
<h4><strong>人体关键点</strong><a class="headerlink" href="#id7" title="Permalink to this heading"></a></h4>
<p>人体关键点识别是一项计算机视觉任务，旨在检测和定位图像或视频中人体的关键位置，通常是关节、身体部位或特定的解剖结构。</p>
<p>这些关键点的检测可以用于人体姿态估计和分类、动作分析、手势识别等多种应用。</p>
<p>XEduHub提供了两个识别人体关键点的优质模型，能够在使用cpu推理的情况下，快速识别出身体的关键点。</p>
<p><code class="docutils literal notranslate"><span class="pre">body17</span></code>和<code class="docutils literal notranslate"><span class="pre">body26</span></code> 数字表示了识别出人体关键点的数量。</p>
<p>声明代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">body</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;body&#39;</span><span class="p">)</span> <span class="c1"># 数字可省略，当省略时，默认为body17</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">body17</span></code>模型能识别出17个人体骨骼关键点，示意图如下，你可以根据自己的需要选择其中的特定的关键点进行后续的处理。</p>
<p><img alt="../_images/body17-sm4.png" src="../_images/body17-sm4.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">body26</span></code>模型能识别出26个人体骨骼关键点，与<code class="docutils literal notranslate"><span class="pre">body17</span></code>相比，示意图如下，你可以根据自己的需要选择其中的特定的关键点进行后续的处理。</p>
<p><img alt="../_images/body26-sm4.png" src="../_images/body26-sm4.png" /></p>
</section>
<section id="id8">
<h4><strong>人脸关键点</strong><a class="headerlink" href="#id8" title="Permalink to this heading"></a></h4>
<p>人脸关键点识别是计算机视觉领域中的一项任务，它的目标是检测和定位人脸图像中代表面部特征的重要点，例如眼睛、鼻子、嘴巴、眉毛等。这些关键点的准确定位对于许多应用非常重要，包括人脸识别、表情分析、虚拟化妆、人机交互等。</p>
<p>XEduHub提供了识别人脸关键点的模型：<code class="docutils literal notranslate"><span class="pre">face106</span></code>，这意味着该模型能够识别人脸上的106个关键点。如下图所示是106个关键点在脸部的分布情况，我们可以利用这些关键点的分布特征进行人脸识别，或者对人的表情进行分析和分类等。</p>
<p><img alt="../_images/face106.png" src="../_images/face106.png" /></p>
<p>声明代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">face</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;face&#39;</span><span class="p">)</span> <span class="c1"># 数字可省略，默认为face106</span>
</pre></div>
</div>
</section>
<section id="id9">
<h4><strong>人手关键点</strong><a class="headerlink" href="#id9" title="Permalink to this heading"></a></h4>
<p>人手关键点识别是一项计算机视觉任务，其目标是检测和定位图像或视频中人手的关键位置，通常包括手指、手掌、手腕等关键部位的位置。这些关键点的识别对于手势识别、手部姿态估计、手部追踪、手势控制设备等应用具有重要意义。</p>
<p>XEduHub提供了能够快速识别人手关键点的模型：<code class="docutils literal notranslate"><span class="pre">hand21</span></code>，该模型能够识别人手上的21个关键点，如下图所示。你可以根据自身需要对关键点进行进一步处理。例如：手势的不同会体现在关键点位置的分布上，这样就可以利用这些关键点进行手势的分类和识别。</p>
<p><img alt="../_images/hand.png" src="../_images/hand.png" /></p>
<p>声明代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hand</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;hand&#39;</span><span class="p">)</span> <span class="c1"># 数字可省略，默认为hand21</span>
</pre></div>
</div>
</section>
<section id="id10">
<h4><strong>人体所有关键点</strong><a class="headerlink" href="#id10" title="Permalink to this heading"></a></h4>
<p>XEduHub提供了识别人体所有关键点，包括人手、人脸和人体躯干部分关键点的模型：<code class="docutils literal notranslate"><span class="pre">wholebody133</span></code>。具体关键点的序号及其分布如下图所示：</p>
<p><img alt="../_images/wholebody.png" src="../_images/wholebody.png" /></p>
<p>声明代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">wholebody</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;wholebody&#39;</span><span class="p">)</span> <span class="c1"># 数字可省略，默认为wholebody133</span>
</pre></div>
</div>
</section>
<section id="id11">
<h4>2. 模型推理<a class="headerlink" href="#id11" title="Permalink to this heading"></a></h4>
<p>由于已经从云端下载好了预训练的SOTA模型，因此只需要传入相应图片即可进行模型推理任务，识别相应的关键点，以人体关键点识别为例，模型推理代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="s2">&quot;data/body.jpg&quot;</span> <span class="c1"># 指定待识别关键点的图片的路径</span>
<span class="n">keypoints</span><span class="p">,</span><span class="n">img_with_keypoints</span> <span class="o">=</span> <span class="n">body</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">img</span><span class="p">,</span><span class="n">img_type</span><span class="o">=</span><span class="s1">&#39;pil&#39;</span><span class="p">)</span> <span class="c1"># 进行模型推理</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">keypoints</span></code>以三维数组的形式保存了所有关键点的坐标，每个关键点(x,y)被表示为<code class="docutils literal notranslate"><span class="pre">[x,y]</span></code>根据前面的图示，要获取到某个特定序号<code class="docutils literal notranslate"><span class="pre">i</span></code>的关键点，只需要访问<code class="docutils literal notranslate"><span class="pre">keypoints[0][i]</span></code>即可。</p>
<p><img alt="../_images/res_keypoints.png" src="../_images/res_keypoints.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">img_with_keypoints</span></code>是个三维数组，以pil格式保存了关键点识别完成后的图片。</p>
<p><img alt="../_images/img_keypoints.png" src="../_images/img_keypoints.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">inference()</span></code>可传入参数：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">data</span></code>: 指定待识别关键点的图片。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">show</span></code>: 可取值：<code class="docutils literal notranslate"><span class="pre">[true,false]</span></code> 默认为<code class="docutils literal notranslate"><span class="pre">false</span></code>。如果取值为<code class="docutils literal notranslate"><span class="pre">true</span></code>，在推理完成后会直接输出关键点识别完成后的图片。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">img_type</span></code>: 关键点识别完成后会返回含有关键点的图片，该参数指定了返回图片的格式，可选有:<code class="docutils literal notranslate"><span class="pre">['cv2','pil']</span></code>，默认值为<code class="docutils literal notranslate"><span class="pre">None</span></code>，如果不传入值，则不会返回图。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bbox</span></code>：该参数可配合目标检测使用。在多人关键点检测中，该参数指定了要识别哪个检测框中的关键点。</p></li>
</ul>
</section>
<section id="id12">
<h4>3. 结果输出<a class="headerlink" href="#id12" title="Permalink to this heading"></a></h4>
<p>XEduHub提供了一种便捷的方式，能够以标准美观的格式查看关键点坐标以及分数（可以理解为置信度），代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">format_result</span> <span class="o">=</span> <span class="n">body</span><span class="o">.</span><span class="n">format_output</span><span class="p">(</span><span class="n">lang</span><span class="o">=</span><span class="s1">&#39;zh&#39;</span><span class="p">)</span><span class="c1"># 参数language设置了输出结果的语言</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">format_result</span></code>以字典形式存储了推理结果，共有两个键：关键点坐标和分数。关键点坐标以二维数组形式保存了每个关键点的[x,y]坐标，而分数则是对应下标的关键点的置信度，以一维数组形式保存。</p>
<p><img alt="../_images/format_output.png" src="../_images/format_output.png" /></p>
<p>显示带有关键点和关键点连线的结果图像</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">body</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">img_with_keypoints</span><span class="p">)</span>
</pre></div>
</div>
<p><img alt="../_images/imgshow-ky.png" src="../_images/imgshow-ky.png" /></p>
</section>
<section id="id13">
<h4>4. 结果保存<a class="headerlink" href="#id13" title="Permalink to this heading"></a></h4>
<p>XEduHub提供了保存带有关键点和关键点连线结果图像的方法，代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">body</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">img_with_keypoints</span><span class="p">,</span><span class="s1">&#39;img_with_keypoints.jpg&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id14">
<h4>5.完整代码<a class="headerlink" href="#id14" title="Permalink to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">XEdu.hub</span> <span class="kn">import</span> <span class="n">Workflow</span> <span class="k">as</span> <span class="n">wf</span>
<span class="n">body</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;body&#39;</span><span class="p">)</span> <span class="c1"># 数字可省略，当省略时，默认为body17</span>
<span class="n">img</span> <span class="o">=</span> <span class="s2">&quot;data/body.jpg&quot;</span> <span class="c1"># 指定待识别关键点的图片的路径</span>
<span class="n">keypoints</span><span class="p">,</span><span class="n">img_with_keypoints</span> <span class="o">=</span> <span class="n">body</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">img</span><span class="p">,</span><span class="n">img_type</span><span class="o">=</span><span class="s1">&#39;pil&#39;</span><span class="p">)</span> <span class="c1"># 进行模型推理</span>
<span class="n">format_result</span> <span class="o">=</span> <span class="n">body</span><span class="o">.</span><span class="n">format_output</span><span class="p">(</span><span class="n">lang</span><span class="o">=</span><span class="s1">&#39;zh&#39;</span><span class="p">)</span><span class="c1"># 参数language设置了输出结果的语言</span>
<span class="n">body</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">img_with_keypoints</span><span class="p">)</span>
<span class="n">body</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">img_with_keypoints</span><span class="p">,</span><span class="s1">&#39;img_with_keypoints.jpg&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="id15">
<h3>方向二：目标检测<a class="headerlink" href="#id15" title="Permalink to this heading"></a></h3>
<p>目标检测是一种计算机视觉任务，其目标是在图像或视频中检测并定位物体的位置，并为每个物体分配类别标签。</p>
<p>实现目标检测通常包括特征提取、物体位置定位、物体类别分类等步骤。这一技术广泛应用于自动驾驶、安全监控、医学影像分析、图像搜索等各种领域，为实现自动化和智能化应用提供了关键支持。</p>
<p><img alt="../_images/objdetection.png" src="../_images/objdetection.png" /></p>
<section id="id16">
<h4>1. 模型声明<a class="headerlink" href="#id16" title="Permalink to this heading"></a></h4>
<p>在第一次声明模型时代码运行用时较长，是因为要将预训练模型从云端下载到本地中，从而便于用户进行使用。</p>
<p>你可以在当前项目中找到名为<strong>checkpoints</strong>的文件夹，里面保存的就是下载下来的预训练模型。</p>
</section>
<section id="id17">
<h4><strong>人体目标检测</strong><a class="headerlink" href="#id17" title="Permalink to this heading"></a></h4>
<p>人体目标检测的任务是在图像或视频中检测和定位人体的位置，并为每个检测到的人体分配一个相应的类别标签。</p>
<p>XEduHub提供了进行人体目标检测的模型：<code class="docutils literal notranslate"><span class="pre">bodydetect</span></code>，该模型能够进行单人的人体目标检测。</p>
<p>声明代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">body_det</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;bodydetect&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="coco">
<h4><strong>coco目标检测</strong><a class="headerlink" href="#coco" title="Permalink to this heading"></a></h4>
<p>COCO（Common Objects in Context）是一个用于目标检测和图像分割任务的广泛使用的数据集和评估基准。它是计算机视觉领域中最重要的数据集之一，在XEduHub中的该模型能够检测出80类coco数据集中的物体：<code class="docutils literal notranslate"><span class="pre">cocodetect</span></code>，声明代码如下:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">coco_det</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;cocodetect&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>若要查看coco目标检测中的所有类别可运行以下代码：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">wf</span><span class="o">.</span><span class="n">coco_class</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="id18">
<h4><strong>人脸检测</strong><a class="headerlink" href="#id18" title="Permalink to this heading"></a></h4>
<p>人脸检测指的是检测和定位一张图片中的人脸。XEduHub使用的是opencv的人脸检测模型，能够快速准确地检测出一张图片中所有的人脸。</p>
<p>需要注意的是由于使用的为opencv的人脸检测模型，因此在<code class="docutils literal notranslate"><span class="pre">format_output</span></code>时缺少了分数这一指标。</p>
<p>声明代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">face_det</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;facedetect&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id19">
<h4>手部检测<a class="headerlink" href="#id19" title="Permalink to this heading"></a></h4>
<p>手部检测指的是检测和定位一张图片中的人手。XEduHub采用的是MMPose框架中rtmpose中的手部检测模型，能够快速准确地检测出图片中的所有人手</p>
<p>声明代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hand_det</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;handdetect&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id20">
<h4>2. 模型推理<a class="headerlink" href="#id20" title="Permalink to this heading"></a></h4>
<p>由于已经从云端下载好了预训练的SOTA模型，因此只需要传入相应图片即可进行模型推理任务，实现目标检测。以人体目标检测为例，模型推理代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="s1">&#39;data/body.jpg&#39;</span>
<span class="n">result</span><span class="p">,</span><span class="n">img_with_box</span> <span class="o">=</span> <span class="n">body_det</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">img</span><span class="p">,</span><span class="n">img_type</span><span class="o">=</span><span class="s1">&#39;cv2&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">result</span></code>以二维数组的形式保存了检测框左上角顶点的(x,y)坐标以及检测框的宽度w和高度h（之所以是二维数组，是因为该模型能够检测多个人体，因此当检测到多个人体时，就会有多个[x,y,w,h]的一维数组，所以需要以二维数组形式保存），我们可以利用这四个数据计算出其他三个顶点的坐标。<img alt="../_images/det_res.png" src="../_images/det_res.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">img_with_box</span></code>是个三维数组，以cv2格式保存了包含了检测框的图片。</p>
<p><img alt="../_images/det_img.png" src="../_images/det_img.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">body_det.inference()</span></code>可传入参数：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">data</span></code>：指定待检测的图片。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">show</span></code>: 可取值：<code class="docutils literal notranslate"><span class="pre">[true,false]</span></code> 默认为<code class="docutils literal notranslate"><span class="pre">false</span></code>。如果取值为<code class="docutils literal notranslate"><span class="pre">true</span></code>，在推理完成后会直接输出目标检测完成后的图片。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">img_type</span></code>：目标检测完成后会返回含有检测框的图片，该参数指定了返回图片的格式，可选有:<code class="docutils literal notranslate"><span class="pre">['cv2','pil']</span></code>，默认值为<code class="docutils literal notranslate"><span class="pre">None</span></code>，如果不传入值，则不会返回图。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">target_class</span></code>：该参数在使用<code class="docutils literal notranslate"><span class="pre">cocodetect</span></code>的时候可以指定要检测的对象，如：<code class="docutils literal notranslate"><span class="pre">person</span></code>，<code class="docutils literal notranslate"><span class="pre">cake</span></code>等等。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">thr</span></code>: 设置检测框阈值，超过该阈值的检测框被视为有效检测框，进行显示。</p></li>
</ul>
</section>
<section id="id21">
<h4>3. 结果输出<a class="headerlink" href="#id21" title="Permalink to this heading"></a></h4>
<p>XEduHub提供了一种便捷的方式，能够以标准美观的格式查看检测框位置信息、检测分数以及目标的分类类别。</p>
<p><code class="docutils literal notranslate"><span class="pre">format_result</span></code>以字典形式存储了推理结果，共有三个键：检测框、分数和类别。检测框以二维数组形式保存了每个检测框的坐标信息[x,y,w,h]，而分数则是对应下标的检测框的置信度，以一维数组形式保存，类别则是检测框中对象所属的类别，以一维数组形式保存。</p>
<p>代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">format_result</span> <span class="o">=</span><span class="n">body_det</span><span class="o">.</span><span class="n">format_output</span><span class="p">(</span><span class="n">lang</span><span class="o">=</span><span class="s1">&#39;zh&#39;</span><span class="p">)</span><span class="c1"># 参数language设置了输出结果的语言</span>
</pre></div>
</div>
<p><img alt="../_images/format_output_person.png" src="../_images/format_output_person.png" /></p>
<p>显示带有检测框的图片</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">body_det</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">img_with_box</span><span class="p">)</span>
</pre></div>
</div>
<p><img alt="../_images/new_body.jpg" src="../_images/new_body.jpg" /></p>
</section>
<section id="id22">
<h4>4. 结果保存<a class="headerlink" href="#id22" title="Permalink to this heading"></a></h4>
<p>XEduHub提供了保存带有检测框图片的方法，代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">body_det</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">img_with_box</span><span class="p">,</span><span class="s1">&#39;img_with_box.jpg&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id23">
<h4>5. 完整代码<a class="headerlink" href="#id23" title="Permalink to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">XEdu.Hub</span> <span class="kn">import</span> <span class="n">Workflow</span> <span class="k">as</span> <span class="n">wf</span>
<span class="n">body_det</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;bodydetect&#39;</span><span class="p">)</span>
<span class="n">img</span> <span class="o">=</span> <span class="s1">&#39;data/body.jpg&#39;</span>
<span class="n">result</span><span class="p">,</span><span class="n">img_with_box</span> <span class="o">=</span> <span class="n">body_det</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">img</span><span class="p">,</span><span class="n">img_type</span><span class="o">=</span><span class="s1">&#39;cv2&#39;</span><span class="p">)</span>
<span class="n">format_result</span> <span class="o">=</span><span class="n">body_det</span><span class="o">.</span><span class="n">format_output</span><span class="p">(</span><span class="n">lang</span><span class="o">=</span><span class="s1">&#39;zh&#39;</span><span class="p">)</span><span class="c1"># 参数language设置了输出结果的语言</span>
<span class="n">body_det</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">img_with_box</span><span class="p">)</span>
<span class="n">body_det</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">img_with_box</span><span class="p">,</span><span class="s1">&#39;img_with_box.jpg&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="ocr">
<h3>方向三：光学字符识别（OCR）<a class="headerlink" href="#ocr" title="Permalink to this heading"></a></h3>
<p>光学字符识别（Optical Character Recognition, OCR）是一项用于将图像或扫描的文档转换为可编辑的文本格式的技术。</p>
<p>OCR技术能够自动识别和提取图像或扫描文档中的文本，并将其转化为计算机可处理的文本格式。</p>
<p>OCR技术在车牌识别、证件识别、文档扫描、拍照搜题等多个场景有着广泛应用。</p>
<section id="id24">
<h4>1. 模型声明<a class="headerlink" href="#id24" title="Permalink to this heading"></a></h4>
<p>XEduHub使用的OCR模型是来自百度的开源免费的OCR模型：rapidocr，这个模型运行速度快，性能优越，小巧灵活，并且能支持超过6000种字符的识别，如简体中文、繁体中文、英文、数字和其他艺术字等等。</p>
<p>注意：你可以在当前项目中找到名为<strong>font</strong>的文件夹，里面的FZVTK.TTF文件是一种字体文件，为了显示识别出的文字而使用。</p>
<p>声明代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ocr</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;ocr&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id25">
<h4>2. 模型推理<a class="headerlink" href="#id25" title="Permalink to this heading"></a></h4>
<p>只需要传入相应图片即可进行字符识别。模型推理代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="s1">&#39;data/ocr.jpg&#39;</span>
<span class="n">result</span><span class="p">,</span><span class="n">ocr_img</span> <span class="o">=</span> <span class="n">ocr</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">img</span><span class="p">,</span><span class="n">img_type</span><span class="o">=</span><span class="s1">&#39;cv2&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">result</span></code>以一维数组的形式保存了识别出的文本及其检测框的四个顶点(x,y)坐标.</p>
<p>如图所示，数组中每个元素的形式为元组：（识别文本，检测框顶点坐标）。四个顶点坐标顺序分别为[左上，右上，左下，右下]。</p>
<p><img alt="../_images/res_ocr.png" src="../_images/res_ocr.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">ocr_img</span></code>的格式为cv2，如下图所示</p>
<p><img alt="../_images/ocr_img.png" src="../_images/ocr_img.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">ocr.inference()</span></code>可传入参数：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">data</span></code>：指定待识别的图片。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">show</span></code>: 可取值：<code class="docutils literal notranslate"><span class="pre">[true,false]</span></code> 默认为<code class="docutils literal notranslate"><span class="pre">false</span></code>。如果取值为<code class="docutils literal notranslate"><span class="pre">true</span></code>，在推理完成后会直接输出OCR完成后的图片。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">img_type</span></code>：目标检测完成后会返回含有检测框的图片，该参数指定了返回图片的格式，可选有:<code class="docutils literal notranslate"><span class="pre">['cv2','pil']</span></code></p></li>
</ul>
</section>
<section id="id26">
<h4>3. 结果输出<a class="headerlink" href="#id26" title="Permalink to this heading"></a></h4>
<p>XEduHub提供了一种便捷的方式，能够以标准美观的格式查看检测框位置信息、分数以及识别出的文本。</p>
<p><code class="docutils literal notranslate"><span class="pre">format_output</span></code>的结果以字典形式存储了推理结果，共有三个键：检测框坐标、分数和文本。检测框坐标以三维数组形式保存了每个检测框的四个顶点的[x,y]坐标，而分数则是对应下标的检测框的置信度，以一维数组形式保存。文本则是每个检测框中识别出的文本，以一维数组形式保存。</p>
<p>代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ocr_format_result</span> <span class="o">=</span> <span class="n">ocr</span><span class="o">.</span><span class="n">format_output</span><span class="p">(</span><span class="n">lang</span><span class="o">=</span><span class="s2">&quot;zh&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><img alt="../_images/ocr_format.png" src="../_images/ocr_format.png" /></p>
<p>显示结果图片：由两部分组成，左侧为原图片，右侧为经过ocr识别出的文本，并且该文本的位置与原图片中文本的位置保持对应。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ocr</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">ocr_img</span><span class="p">)</span>
</pre></div>
</div>
<p><img alt="../_images/ocr_6_img.png" src="../_images/ocr_6_img.png" /></p>
</section>
<section id="id27">
<h4>4. 结果保存<a class="headerlink" href="#id27" title="Permalink to this heading"></a></h4>
<p>XEduHub提供了保存OCR识别后的图片的方法，代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ocr</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">ocr_img</span><span class="p">,</span><span class="s2">&quot;ocr_img.jpg&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id28">
<h4>5. 完整代码<a class="headerlink" href="#id28" title="Permalink to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">XEdu.Hub</span> <span class="kn">import</span> <span class="n">Workflow</span> <span class="k">as</span> <span class="n">wf</span>
<span class="n">ocr</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;ocr&quot;</span><span class="p">)</span>
<span class="n">img</span> <span class="o">=</span> <span class="s1">&#39;data/ocr.jpg&#39;</span>
<span class="n">result</span><span class="p">,</span><span class="n">ocr_img</span> <span class="o">=</span> <span class="n">ocr</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">img</span><span class="p">,</span><span class="n">img_type</span><span class="o">=</span><span class="s1">&#39;cv2&#39;</span><span class="p">)</span>
<span class="n">ocr_format_result</span> <span class="o">=</span> <span class="n">ocr</span><span class="o">.</span><span class="n">format_output</span><span class="p">(</span><span class="n">lang</span><span class="o">=</span><span class="s2">&quot;zh&quot;</span><span class="p">)</span>
<span class="n">ocr</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">ocr_img</span><span class="p">)</span>
<span class="n">ocr</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">ocr_img</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="id29">
<h2>外置任务<a class="headerlink" href="#id29" title="Permalink to this heading"></a></h2>
<p>XEduHub除了内置多个深度学习领域优质的SOTA模型，支持多种类型的内置任务，同时也支持指定外置任务，如MMEdu、BaseNN。</p>
<section id="mmedu">
<h3>基于MMEdu导出模型推理<a class="headerlink" href="#mmedu" title="Permalink to this heading"></a></h3>
<p>XEduHub现在可以支持使用MMEdu导出的onnx模型进行推理啦！如果你想了解如何将使用<a class="reference external" href="https://xedu.readthedocs.io/zh/master/mmedu.html">MMEdu</a>训练好的模型转换成ONNX格式，可以看这里<a class="reference external" href="https://xedu.readthedocs.io/zh/master/mmedu/model_convert.html">最后一步：AI模型转换</a>。OK，准备好了ONNX模型，那么就开始使用XEduHub吧！</p>
<section id="id30">
<h4>1. 模型声明<a class="headerlink" href="#id30" title="Permalink to this heading"></a></h4>
<p>与外置任务的模型声明不同之处在于：<code class="docutils literal notranslate"><span class="pre">task</span></code>和<code class="docutils literal notranslate"><span class="pre">checkpoint</span></code>的设置。首先，你只需要设置task为”mmedu”，而不需要指定是哪种任务；其次，你需要指定你的模型的路径，并传入到<code class="docutils literal notranslate"><span class="pre">checkpoint</span></code>参数。这里我们以猫狗分类模型为例，项目指路：<a class="reference external" href="https://www.openinnolab.org.cn/pjlab/project?id=63c756ad2cf359369451a617&amp;sc=647b3880aac6f67c822a04f5#public">猫狗分类</a>。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mmedu</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;mmedu&quot;</span><span class="p">,</span><span class="n">checkpoint</span><span class="o">=</span><span class="s2">&quot;cat_dogs.onnx&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id31">
<h4>2. 模型推理<a class="headerlink" href="#id31" title="Permalink to this heading"></a></h4>
<p>在完成模型声明后，传入待推理的数据即可完成推理。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="s1">&#39;cat.jpg&#39;</span>
<span class="n">result</span><span class="p">,</span> <span class="n">new_img</span> <span class="o">=</span>  <span class="n">mmedu</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">img</span><span class="p">,</span><span class="n">img_type</span><span class="o">=</span><span class="s2">&quot;pil&quot;</span><span class="p">,</span><span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p><img alt="../_images/mmedu_inference.png" src="../_images/mmedu_inference.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">mmedu.inference</span></code>可传入参数：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">data</span></code>：指定待检测的图片。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">show</span></code>: 可取值：<code class="docutils literal notranslate"><span class="pre">[true,false]</span></code> 默认为<code class="docutils literal notranslate"><span class="pre">false</span></code>。如果取值为<code class="docutils literal notranslate"><span class="pre">true</span></code>，在推理完成后会直接输出目标检测完成后的图片。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">img_type</span></code>：目标检测完成后会返回含有检测框的图片，该参数指定了返回图片的格式，可选有:<code class="docutils literal notranslate"><span class="pre">['cv2','pil']</span></code>，默认值为<code class="docutils literal notranslate"><span class="pre">None</span></code>，如果不传入值，则不会返回图。</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">result</span></code>和<code class="docutils literal notranslate"><span class="pre">img</span></code>是模型推理后返回的推理结果。</p>
<p><code class="docutils literal notranslate"><span class="pre">result</span></code>结果如下图所示，是一个一维数组，这代表着每个分类标签的置信度，第一个元素是这张图片为猫的置信度，第二个元素是这张图片为狗的置信度，显然，这张图片为猫的置信度接近100%，自然这张图片被分类为猫。</p>
<p><img alt="../_images/mmedu_res.png" src="../_images/mmedu_res.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">img</span></code>结果是打上分类标签和分数的原图片，在这里以数字化的方式（三维数组）呈现。</p>
<p><img alt="../_images/mmedu_img.png" src="../_images/mmedu_img.png" /></p>
</section>
<section id="id32">
<h4>3. 结果输出<a class="headerlink" href="#id32" title="Permalink to this heading"></a></h4>
<p>XEduHub提供了一种便捷的方式，能够以标准美观的格式查看输出结果。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">format_result</span> <span class="o">=</span> <span class="n">mmedu</span><span class="o">.</span><span class="n">format_output</span><span class="p">(</span><span class="n">lang</span><span class="o">=</span><span class="s2">&quot;zh&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><img alt="../_images/mmedu_format.png" src="../_images/mmedu_format.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">format_result</span></code>以字典形式保存了模型的推理结果，包括所属标签、置信度、以及预测结果。</p>
<p>显示结果图片：与原图相比，结果图片在左上角多了<code class="docutils literal notranslate"><span class="pre">pred_label</span></code>, <code class="docutils literal notranslate"><span class="pre">pred_socre</span></code>和<code class="docutils literal notranslate"><span class="pre">pred_class</span></code>三个数据，对应着标签、置信度和预测结果。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mmedu</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">new_img</span><span class="p">,</span><span class="s2">&quot;mmedu_img.jpg&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><img alt="../_images/mmedu_show.png" src="../_images/mmedu_show.png" /></p>
</section>
<section id="id33">
<h4>4. 结果保存<a class="headerlink" href="#id33" title="Permalink to this heading"></a></h4>
<p>XEduHub提供了保存MMEdu模型推理后的图片的方法，代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mmedu</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="s1">&#39;new_cat.jpg&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id34">
<h4>5. 指定其他<a class="headerlink" href="#id34" title="Permalink to this heading"></a></h4>
<p>XEduHub提供了保存MMEdu模型推</p>
<p>如果此时你有冲动去使用MMEdu完成模型训练到推理，再到转换与应用，快去下文学习<a class="reference external" href="https://xedu.readthedocs.io/zh/master/mmedu.html">MMEdu的相关使用</a>吧！</p>
</section>
</section>
<section id="basenn">
<h3>基于BaseNN导出模型推理<a class="headerlink" href="#basenn" title="Permalink to this heading"></a></h3>
<p>XEduHub现在可以支持使用BaseNN导出的onnx模型进行推理啦！如果你想了解如何将使用<a class="reference external" href="https://xedu.readthedocs.io/zh/master/basenn.html">BaseNN</a>训练好的模型转换成ONNX格式，可以看这里：<a class="reference external" href="https://xedu.readthedocs.io/zh/master/basenn/introduction.html#id29">BaseNN模型文件格式转换</a>。OK，准备好了ONNX模型，那么就开始使用XEduHub吧！</p>
<section id="id35">
<h4>1. 模型声明<a class="headerlink" href="#id35" title="Permalink to this heading"></a></h4>
<p>与MMEdu一样，在模型声明时你只需要设置task为”basenn”，而不需要指定是哪种任务；其次，你需要指定你的模型的路径，并传入到<code class="docutils literal notranslate"><span class="pre">checkpoint</span></code>参数。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">basenn</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;basenn&quot;</span><span class="p">,</span><span class="n">checkpoint</span><span class="o">=</span><span class="s2">&quot;basenn.pth&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id36">
<h4>2. 模型推理<a class="headerlink" href="#id36" title="Permalink to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="s1">&#39;6.jpg&#39;</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">base</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">img</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">result</span></code>结果如下图所示，是一个一维数组，这代表着每个分类标签的概率。显然可以看到数字为6的标签的置信度最高，是1.0。</p>
<p><img alt="../_images/basenn_res.png" src="../_images/basenn_res.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">mmedu.inference</span></code>可传入参数：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">data</span></code>：指定待检测的图片。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">show</span></code>: 可取值：<code class="docutils literal notranslate"><span class="pre">[true,false]</span></code> 默认为<code class="docutils literal notranslate"><span class="pre">false</span></code>。如果取值为<code class="docutils literal notranslate"><span class="pre">true</span></code>，在推理完成后会直接输出目标检测完成后的图片。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">img_type</span></code>：目标检测完成后会返回含有检测框的图片，该参数指定了返回图片的格式，可选有:<code class="docutils literal notranslate"><span class="pre">['cv2','pil']</span></code>，默认值为<code class="docutils literal notranslate"><span class="pre">None</span></code>，如果不传入值，则不会返回图。</p></li>
</ul>
<p>**注意！**基于BaseNN模型推理结果不包含图片！因为大部分使用BaseNN解决的任务只需要输出分类标签、文本或者数组数据等。</p>
</section>
<section id="id37">
<h4>3. 结果输出<a class="headerlink" href="#id37" title="Permalink to this heading"></a></h4>
<p>XEduHub提供了一种便捷的方式，能够以标准美观的格式查看输出结果。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">format_output</span> <span class="o">=</span> <span class="n">basenn</span><span class="o">.</span><span class="n">format_output</span><span class="p">(</span><span class="n">lang</span><span class="o">=</span><span class="s1">&#39;zh&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">format_result</span></code>以字典形式保存了模型的推理结果，包括预测结果，分数（置信度）。</p>
<p>如果此时你有冲动去使用BaseNN完成模型训练到推理，再到转换与应用，快去下文学习<a class="reference external" href="https://xedu.readthedocs.io/zh/master/basenn.html">BaseNN的相关使用</a>吧！</p>
</section>
</section>
<section id="id38">
<h3>基于用户自定义模型推理<a class="headerlink" href="#id38" title="Permalink to this heading"></a></h3>
<p>即将上线，敬请期待！</p>
</section>
</section>
<section id="ai">
<h2>多元AI模型综合应用<a class="headerlink" href="#ai" title="Permalink to this heading"></a></h2>
<p>借助XEduHub可以实现应用多元AI模型去解决复杂的问题。</p>
<section id="id39">
<h3>实时人体关键点识别<a class="headerlink" href="#id39" title="Permalink to this heading"></a></h3>
<p>以下代码可以实时检测摄像头中出现的多个人，并对每一个人体提取关键点。</p>
<p>具体实现方式为：我们首先将实时视频中每一帧的图像进行人体目标检测，拿到所有的检测框<code class="docutils literal notranslate"><span class="pre">bbox</span></code>及其坐标信息，绘制检测框。随后对每个检测框中的人体进行关键点提取。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">XEdu.hub</span> <span class="kn">import</span> <span class="n">Workflow</span> <span class="k">as</span> <span class="n">wf</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="n">cap</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">body</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;body17&#39;</span><span class="p">)</span><span class="c1"># 实例化pose模型</span>
<span class="n">det</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;bodydetect&#39;</span><span class="p">)</span><span class="c1"># 实例化detect模型</span>
<span class="k">while</span> <span class="n">cap</span><span class="o">.</span><span class="n">isOpened</span><span class="p">():</span>
    <span class="n">ret</span><span class="p">,</span> <span class="n">frame</span> <span class="o">=</span> <span class="n">cap</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">ret</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="n">bboxs</span> <span class="o">=</span> <span class="n">det</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">frame</span><span class="p">,</span><span class="n">thr</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">frame</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">bboxs</span><span class="p">:</span>
        <span class="n">keypoints</span><span class="p">,</span><span class="n">img</span> <span class="o">=</span><span class="n">body</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">img</span><span class="p">,</span><span class="n">img_type</span><span class="o">=</span><span class="s1">&#39;cv2&#39;</span><span class="p">,</span><span class="n">bbox</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
    <span class="k">for</span> <span class="p">[</span><span class="n">x1</span><span class="p">,</span><span class="n">y1</span><span class="p">,</span><span class="n">x2</span><span class="p">,</span><span class="n">y2</span><span class="p">]</span> <span class="ow">in</span> <span class="n">bboxs</span><span class="p">:</span> <span class="c1"># 画检测框</span>
        <span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">x1</span><span class="p">),</span><span class="nb">int</span><span class="p">(</span><span class="n">y1</span><span class="p">)),(</span><span class="nb">int</span><span class="p">(</span><span class="n">x2</span><span class="p">),</span><span class="nb">int</span><span class="p">(</span><span class="n">y2</span><span class="p">)),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">255</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s1">&#39;video&#39;</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="mh">0xFF</span> <span class="o">==</span> <span class="nb">ord</span><span class="p">(</span><span class="s1">&#39;q&#39;</span><span class="p">):</span>
        <span class="k">break</span>    
<span class="n">cap</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">destroyAllWindows</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="id40">
<h3><strong>拓展：视频中的人体关键点识别</strong><a class="headerlink" href="#id40" title="Permalink to this heading"></a></h3>
<p>该项目可以识别视频中出现的人体的关键点。</p>
<p>具体实现方式与上面的代码类似，区别就是从摄像头的实时视频流变成了本地的视频流，对视频每一帧的操作不变。最后，我们还需要将处理好的每一帧的图片再合成为视频。</p>
<p>在这里我们将这个任务分成两步：Step1: 利用关键点识别处理视频的每一帧并保存到本地；Step2: 将本地的视频帧合成为视频。</p>
<p>Step1的代码：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># STEP1: 利用关键点识别处理视频的每一帧并保存到本地</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">from</span> <span class="nn">XEdu.hub</span> <span class="kn">import</span> <span class="n">Workflow</span> <span class="k">as</span> <span class="n">wf</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="n">video_path</span> <span class="o">=</span> <span class="s2">&quot;data/eason.mp4&quot;</span> <span class="c1"># 指定视频路径</span>
<span class="n">output_dir</span> <span class="o">=</span> <span class="s1">&#39;output/&#39;</span> <span class="c1"># 指定保存位置</span>
<span class="n">body</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;body17&#39;</span><span class="p">)</span><span class="c1"># 实例化pose模型</span>
<span class="n">det</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;bodydetect&#39;</span><span class="p">)</span><span class="c1"># 实例化detect模型</span>
<span class="n">cap</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="n">video_path</span><span class="p">)</span>
<span class="n">frame_count</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># 视频帧的数量</span>

<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">ret</span><span class="p">,</span> <span class="n">frame</span> <span class="o">=</span> <span class="n">cap</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">ret</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Video read complete!&#39;</span><span class="p">)</span>
        <span class="k">break</span>
    <span class="n">frame_count</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">frame_file_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">output_dir</span><span class="si">}</span><span class="s1">frame_</span><span class="si">{</span><span class="n">frame_count</span><span class="si">:</span><span class="s1">04d</span><span class="si">}</span><span class="s1">.jpg&#39;</span> <span class="c1"># 每一张帧图片的名称</span>
    <span class="n">bboxs</span> <span class="o">=</span> <span class="n">det</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">frame</span><span class="p">,</span><span class="n">thr</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">frame</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">bboxs</span><span class="p">:</span>
        <span class="n">keypoints</span><span class="p">,</span><span class="n">img</span> <span class="o">=</span><span class="n">body</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">img</span><span class="p">,</span><span class="n">img_type</span><span class="o">=</span><span class="s1">&#39;cv2&#39;</span><span class="p">,</span><span class="n">bbox</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
    <span class="k">for</span> <span class="p">[</span><span class="n">x1</span><span class="p">,</span><span class="n">y1</span><span class="p">,</span><span class="n">x2</span><span class="p">,</span><span class="n">y2</span><span class="p">]</span> <span class="ow">in</span> <span class="n">bboxs</span><span class="p">:</span> <span class="c1"># 画检测框</span>
        <span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">x1</span><span class="p">),</span><span class="nb">int</span><span class="p">(</span><span class="n">y1</span><span class="p">)),(</span><span class="nb">int</span><span class="p">(</span><span class="n">x2</span><span class="p">),</span><span class="nb">int</span><span class="p">(</span><span class="n">y2</span><span class="p">)),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">255</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s1">&#39;video&#39;</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>
    <span class="n">body</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="n">frame_file_name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="mh">0xFF</span> <span class="o">==</span> <span class="nb">ord</span><span class="p">(</span><span class="s1">&#39;q&#39;</span><span class="p">):</span>
        <span class="k">break</span>    

<span class="n">cap</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
</pre></div>
</div>
<p>Step2的代码：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="n">output_video_path</span> <span class="o">=</span> <span class="s1">&#39;output_video.mp4&#39;</span> <span class="c1"># 指定合成后视频的名称</span>
<span class="n">output_dir</span> <span class="o">=</span> <span class="s1">&#39;output/&#39;</span> <span class="c1"># 指定本地的帧图片的路径</span>
<span class="c1"># 获取推理结果文件列表</span>
<span class="n">result_files</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span> <span class="k">if</span> <span class="n">f</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;.jpg&#39;</span><span class="p">)])</span>
<span class="c1"># 获取第一张图像的尺寸</span>
<span class="n">first_frame</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">result_files</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">frame_height</span><span class="p">,</span> <span class="n">frame_width</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">first_frame</span><span class="o">.</span><span class="n">shape</span>
<span class="c1"># 设置视频编码器和输出对象</span>
<span class="n">fourcc</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoWriter_fourcc</span><span class="p">(</span><span class="o">*</span><span class="s1">&#39;mp4v&#39;</span><span class="p">)</span>  <span class="c1"># 使用 mp4 编码器</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoWriter</span><span class="p">(</span><span class="n">output_video_path</span><span class="p">,</span> <span class="n">fourcc</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="p">(</span><span class="n">frame_width</span><span class="p">,</span> <span class="n">frame_height</span><span class="p">))</span> <span class="c1"># 30 是帧率</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;开始合成视频...&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">image_path</span> <span class="ow">in</span> <span class="n">result_files</span><span class="p">:</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
    <span class="n">out</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">out</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;视频合成完毕，已保存到：&#39;</span><span class="p">,</span> <span class="n">output_video_path</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id41">
<h3>多人脸关键点识别<a class="headerlink" href="#id41" title="Permalink to this heading"></a></h3>
<p>以下代码可以将一张图片中所有的人脸识别出来，并对每一张脸提取关键点。这可以用于对一张图片中的所有人进行表情分类，推测情感等。</p>
<p>具体实现方式为：我们首先使用<code class="docutils literal notranslate"><span class="pre">facedetect</span></code>进行人脸检测，拿到所有的检测框<code class="docutils literal notranslate"><span class="pre">bbox</span></code>。随后对每个检测框中的人脸进行关键点提取。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">XEdu.hub</span> <span class="kn">import</span> <span class="n">Workflow</span> <span class="k">as</span> <span class="n">wf</span>
<span class="n">face_det</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;facedetect&#39;</span><span class="p">)</span>
<span class="n">face_kp</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;face&#39;</span><span class="p">)</span>
<span class="n">bboxs</span><span class="p">,</span><span class="n">img</span> <span class="o">=</span> <span class="n">face_det</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="s1">&#39;face.jpg&#39;</span><span class="p">,</span><span class="n">img_type</span><span class="o">=</span><span class="s1">&#39;cv2&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">bboxs</span><span class="p">:</span>
    <span class="n">keypoints</span><span class="p">,</span><span class="n">img</span> <span class="o">=</span> <span class="n">face_kp</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">img</span><span class="p">,</span><span class="n">img_type</span><span class="o">=</span><span class="s1">&#39;cv2&#39;</span><span class="p">,</span><span class="n">bbox</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
    <span class="n">face_kp</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id42">
<h3>人脸检测控制舵机方向<a class="headerlink" href="#id42" title="Permalink to this heading"></a></h3>
<p>以下代码可以运行在Arduino开发板上，实现通过跟随人脸位置来控制舵机方向。具体实现方式为：通过人脸检测模型得到人脸检测框的坐标并计算x轴方向的中心点，根据中心点的位置判断是左转还是右转。通过pinpong库控制舵机的转向。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">from</span> <span class="nn">pinpong.board</span> <span class="kn">import</span> <span class="n">Board</span><span class="p">,</span> <span class="n">Pin</span><span class="p">,</span> <span class="n">Servo</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">XEdu.hub</span> <span class="kn">import</span> <span class="n">Workflow</span> <span class="k">as</span> <span class="n">wf</span>
<span class="kn">import</span> <span class="nn">time</span>


<span class="n">Board</span><span class="p">(</span><span class="s1">&#39;uno&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">begin</span><span class="p">()</span> <span class="c1"># 指定Arduino开发板，自动识别COM口</span>
<span class="n">det</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;facedetect&#39;</span><span class="p">)</span> <span class="c1"># 加载人脸检测模型</span>
<span class="n">ser</span> <span class="o">=</span> <span class="n">Servo</span><span class="p">(</span><span class="n">Pin</span><span class="p">(</span><span class="n">Pin</span><span class="o">.</span><span class="n">D4</span><span class="p">))</span> <span class="c1"># 初始化舵机，指定舵机接口为D4</span>
<span class="n">cap</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># 打开摄像头</span>

<span class="k">while</span> <span class="n">cap</span><span class="o">.</span><span class="n">isOpened</span><span class="p">():</span>
    <span class="n">ret</span><span class="p">,</span> <span class="n">frame</span> <span class="o">=</span> <span class="n">cap</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="n">x</span> <span class="o">=</span> <span class="mi">300</span> <span class="c1"># 初始化人脸中心点的x坐标</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">ret</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="n">result</span><span class="p">,</span><span class="n">img</span> <span class="o">=</span> <span class="n">det</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">frame</span><span class="p">,</span><span class="n">img_type</span><span class="o">=</span><span class="s1">&#39;cv2&#39;</span><span class="p">,</span><span class="n">thr</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span> <span class="c1"># 在CPU上进行推理</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span><span class="o">+</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># 计算人脸中心点的x坐标</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">400</span><span class="p">:</span> <span class="c1"># 根据人脸中心点的x坐标控制舵机转动,大于400向左转</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.05</span><span class="p">)</span>
        <span class="n">ser</span><span class="o">.</span><span class="n">write_angle</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="mi">200</span><span class="p">:</span> <span class="c1"># 根据人脸中心点的x坐标控制舵机转动，小于200向右转</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.05</span><span class="p">)</span>
        <span class="n">ser</span><span class="o">.</span><span class="n">write_angle</span><span class="p">(</span><span class="mi">180</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;right&#39;</span><span class="p">)</span>
    <span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s1">&#39;video&#39;</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="mh">0xFF</span> <span class="o">==</span> <span class="nb">ord</span><span class="p">(</span><span class="s1">&#39;q&#39;</span><span class="p">):</span> <span class="c1"># 按q键退出</span>
        <span class="k">break</span>    
<span class="n">cap</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">destroyAllWindows</span><span class="p">()</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="installation.html" class="btn btn-neutral float-left" title="XEduHub安装" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../mmedu.html" class="btn btn-neutral float-right" title="计算机视觉库MMEdu" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021-2023 OpenXLabEdu.All Rights Reserved.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>