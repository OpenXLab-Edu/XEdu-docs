<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>XEdu-Hub功能详解 &mdash; OpenXLabEdu  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> OpenXLabEdu
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">目录</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../about.html">关于XEdu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mmedu.html">计算机视觉库MMEdu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basenn.html">神经网络库BaseNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../baseml.html">传统机器学习库BaseML</a></li>
<li class="toctree-l1"><a class="reference internal" href="../easydl.html">EasyDL系列无代码工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basedt.html">数据处理库BaseDT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basedeploy.html">模型部署库BaseDeploy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scitech_tools.html">相关科创工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="../support_resources.html">学习支持和资源获取</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dl_library.html">深度学习知识库</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">OpenXLabEdu</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>XEdu-Hub功能详解</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/xedu-hub/introduction.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="xedu-hub">
<h1>XEdu-Hub功能详解<a class="headerlink" href="#xedu-hub" title="Permalink to this headline"></a></h1>
<section id="id1">
<h2>为什么是XEdu-Hub？<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h2>
<p>XEdu-Hub是一个专为快速、便捷地利用最先进的深度学习模型完成任务而设计的工具库。其设计灵感源自PyTorchHub，旨在以工作流的方式，迅速高效地完成深度学习任务。XEdu-Hub的独特之处在于它内置了大量优质的深度学习SOTA模型，无需用户自行进行繁琐的模型训练。用户只需将这些现成的模型应用于特定任务，便能轻松进行AI应用实践。</p>
<p>XEdu-Hub的目标是为学习者提供一个无需深入研究底层算法和模型构建的解决方案。通过将各种最新的深度学习模型集成到库中，XEdu-Hub赋予用户能力，使他们能够专注于任务本身，而不必担心模型训练、调优等繁杂的工作。这使得教育者、研究者和从业者都能够更容易地将深度学习技术应用于实际问题，从而推动AI应用的便捷性和普及度。</p>
<p>XEdu-Hub的设计理念在于让深度学习任务变得更加容易，允许用户通过简单地引用现有的SOTA模型，而不必从头开始构建自己的模型，从而为学习者和从业者提供了更便捷的AI应用实践体验。</p>
</section>
<section id="id2">
<h2>解锁XEdu-Hub的使用方法<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h2>
<p>XEdu-Hub作为一个深度学习工具库，集成了许多深度学习领域优质的SOTA模型，能够帮助用户在不进模型训练的前提下，用少量的代码，快速实现计算机视觉、自然语言处理等多个深度学习领域的任务。</p>
</section>
<section id="id3">
<h2>计算机视觉<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h2>
<section id="id4">
<h3>关键点识别<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h3>
<p>关键点识别是深度学习中的一项关键任务，旨在检测图像或视频中的关键位置，通常代表物体或人体的重要部位。</p>
<p>关键点识别在众多领域中有着广泛的应用，包括人脸识别、人体姿态估计、虚拟现实等。虽然面临遮挡、姿态变化等挑战，但研究人员不断改进模型和训练策略，以提高准确性和稳定性，推动了计算机视觉和人机交互领域的进步。</p>
<p>关键点识别的成功应用有望进一步丰富我们对图像和视频数据的理解。</p>
<section id="id5">
<h4>0. 引入库<a class="headerlink" href="#id5" title="Permalink to this headline"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">XEdu.hub</span> <span class="kn">import</span> <span class="n">Workflow</span> <span class="k">as</span> <span class="n">wf</span>
</pre></div>
</div>
<p>运行代码<code class="docutils literal notranslate"><span class="pre">wf.support_task()</span></code>即可查看当前支持的深度学习任务。</p>
</section>
<section id="id6">
<h4>1. 模型声明<a class="headerlink" href="#id6" title="Permalink to this headline"></a></h4>
<p>在第一次声明模型时代码运行用时较长，是因为要将预训练模型从云端下载到本地中，从而便于用户进行使用。</p>
<section id="id7">
<h5>人体关键点<a class="headerlink" href="#id7" title="Permalink to this headline"></a></h5>
<p>人体关键点识别是一项计算机视觉任务，旨在检测和定位图像或视频中人体的关键位置，通常是关节、身体部位或特定的解剖结构。</p>
<p>这些关键点的检测可以用于人体姿态估计和分类、动作分析、手势识别等多种应用。</p>
<p>XEdu-Hub提供了两个识别人体关键点的模型，<code class="docutils literal notranslate"><span class="pre">body17</span></code>和<code class="docutils literal notranslate"><span class="pre">body26</span></code> 数字表示了识别出人体关键点的数量，声明代码如下</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pose</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;body&#39;</span><span class="p">)</span> <span class="c1"># 数字可省略，当省略时，默认为body17</span>
</pre></div>
</div>
</section>
<section id="id8">
<h5>人脸关键点<a class="headerlink" href="#id8" title="Permalink to this headline"></a></h5>
<p>人脸关键点识别是计算机视觉领域中的一项任务，它的目标是检测和定位人脸图像中的关键点，通常是代表面部特征的重要点，</p>
<p>例如眼睛、鼻子、嘴巴、眉毛等。这些关键点的准确定位对于许多应用非常重要，包括人脸识别、表情分析、虚拟化妆、人机交互等。</p>
<p>XEdu-Hub提供了识别人脸关键点的模型：<code class="docutils literal notranslate"><span class="pre">face106</span></code>，这意味着该模型能够识别人脸上的106个关键点，声明代码如下</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pose</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;face&#39;</span><span class="p">)</span> <span class="c1"># 数字可省略，默认为face106</span>
</pre></div>
</div>
</section>
<section id="id9">
<h5>人手关键点<a class="headerlink" href="#id9" title="Permalink to this headline"></a></h5>
<p>人手关键点识别是一项计算机视觉任务，其目标是检测和定位图像或视频中人手的关键位置，通常包括手指、手掌、手腕等关键部位的位置。</p>
<p>这些关键点的识别对于手势识别、手部姿态估计、手部追踪、手势控制设备等应用具有重要意义。</p>
<p>XEdu-Hub提供了识别人手关键点的模型：<code class="docutils literal notranslate"><span class="pre">hand21</span></code>，该模型能够识别人手上的21个关键点，声明代码如下</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pose</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;hand&#39;</span><span class="p">)</span> <span class="c1"># 数字可省略，默认为hand21</span>
</pre></div>
</div>
</section>
<section id="id10">
<h5>人体所有关键点<a class="headerlink" href="#id10" title="Permalink to this headline"></a></h5>
<p>XEdu-Hub提供了识别人体所有关键点，包括人手、人脸和人体躯干部分关键点的模型：<code class="docutils literal notranslate"><span class="pre">wholebody133</span></code>，声明代码如下</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pose</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;wholebody&#39;</span><span class="p">)</span> <span class="c1"># 数字可省略，默认为wholebody133</span>
</pre></div>
</div>
</section>
</section>
<section id="id11">
<h4>2. 模型推理<a class="headerlink" href="#id11" title="Permalink to this headline"></a></h4>
<p>由于已经从云端下载好了预训练的SOTA模型，因此只需要传入相应图片即可进行模型推理任务，识别相应的关键点，以人体关键点识别为例，模型推理代码如下</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="s2">&quot;data/body.jpg&quot;</span> <span class="c1"># 指定待识别关键点的图片的路径</span>
<span class="n">keypoints</span><span class="p">,</span><span class="n">img_with_keypoints</span> <span class="o">=</span> <span class="n">pose</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">img</span><span class="p">,</span><span class="n">img_type</span><span class="o">=</span><span class="s1">&#39;pil&#39;</span><span class="p">)</span> <span class="c1"># 进行模型推理</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">keypoints</span></code>保存了所有关键点的坐标，<code class="docutils literal notranslate"><span class="pre">img</span></code>以pil格式保存了关键点识别完成后的图片</p>
<p><code class="docutils literal notranslate"><span class="pre">pose.inference()</span></code>可传入参数：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">data</span></code>: 指定待识别关键点的图片</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">img_type</span></code>: 关键点识别完成后会返回含有关键点的图片，该参数指定了返回图片的格式，可选有:<code class="docutils literal notranslate"><span class="pre">['cv2','pil']</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bbox</span></code>：该参数可配合目标检测使用。在多人关键点检测中，该参数指定了要识别哪个检测框中的关键点</p></li>
</ul>
</section>
<section id="id12">
<h4>3. 结果输出<a class="headerlink" href="#id12" title="Permalink to this headline"></a></h4>
<p>XEdu-Hub提供了一种便捷的方式，能够以标准美观的格式查看关键点坐标以及分数（可以理解为置信度），代码如下</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">format_result</span> <span class="o">=</span> <span class="n">pose</span><span class="o">.</span><span class="n">format_output</span><span class="p">(</span><span class="n">lang</span><span class="o">=</span><span class="s1">&#39;zh&#39;</span><span class="p">)</span><span class="c1"># 参数language设置了输出结果的语言</span>
</pre></div>
</div>
<p>显示带有关键点和关键点连线的结果图像</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pose</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">img_with_keypoints</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id13">
<h4>4. 结果保存<a class="headerlink" href="#id13" title="Permalink to this headline"></a></h4>
<p>XEdu-Hub提供了保存带有关键点和关键点连线结果图像的方法，代码如下</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pose</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">img_with_keypoints</span><span class="p">,</span><span class="s1">&#39;img_with_keypoints.jpg&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="id14">
<h3>目标检测<a class="headerlink" href="#id14" title="Permalink to this headline"></a></h3>
<p>目标检测是一种计算机视觉任务，其目标是在图像或视频中检测并定位物体的位置，并为每个物体分配类别标签。</p>
<p>实现目标检测通常包括特征提取、物体位置定位、物体类别分类等步骤。这一技术广泛应用于自动驾驶、安全监控、人脸识别、医学影像分析、虚拟现实、图像搜索等各种领域，为实现自动化和智能化应用提供了关键支持。</p>
<section id="id15">
<h4>0. 引入库<a class="headerlink" href="#id15" title="Permalink to this headline"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">XEdu.hub</span> <span class="kn">import</span> <span class="n">Workflow</span> <span class="k">as</span> <span class="n">wf</span>
</pre></div>
</div>
<p>运行代码<code class="docutils literal notranslate"><span class="pre">wf.support_task()</span></code>即可查看当前支持的深度学习任务。</p>
</section>
<section id="id16">
<h4>1. 模型声明<a class="headerlink" href="#id16" title="Permalink to this headline"></a></h4>
<p>在第一次声明模型时代码运行用时较长，是因为要将预训练模型从云端下载到本地中，从而便于用户进行使用。</p>
<section id="id17">
<h5>人体目标检测<a class="headerlink" href="#id17" title="Permalink to this headline"></a></h5>
<p>人体目标检测是目标检测的一个领域，它的任务是在图像或视频中检测和定位人体的位置，并为每个检测到的人体分配一个相应的类别标签。</p>
<p>通常，人体目标检测不仅要求准确地定位人体的边界框，还需要对人体进行类别分类，如行人、车辆乘客、骑自行车者等。这一技术在自动驾驶、视频监控、行人识别、人数统计、人体姿态估计等领域中有广泛的应用。</p>
<p>XEdu-Hub提供了进行人体目标检测的模型：<code class="docutils literal notranslate"><span class="pre">bodydetect</span></code>，该模型既能够进行单人的人体目标检测，也能够实现多人检测，声明代码如下</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">det</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;bodydetect&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="coco">
<h5>coco目标检测<a class="headerlink" href="#coco" title="Permalink to this headline"></a></h5>
<p>COCO（Common Objects in Context）是一个用于目标检测和图像分割任务的广泛使用的数据集和评估基准。它是计算机视觉领域中最重要的数据集之一，在XEdu-Hub中的该模型能够检测出80类coco数据集中的物体：<code class="docutils literal notranslate"><span class="pre">cocodetect</span></code>，声明代码如下</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;cocodetect&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>若要查看coco目标检测中的所有类别可运行以下代码</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">wf</span><span class="o">.</span><span class="n">coco_class</span><span class="p">()</span>
</pre></div>
</div>
</section>
</section>
<section id="id18">
<h4>2. 模型推理<a class="headerlink" href="#id18" title="Permalink to this headline"></a></h4>
<p>由于已经从云端下载好了预训练的SOTA模型，因此只需要传入相应图片即可进行模型推理任务，识别相应的关键点，以人体目标检测为例，模型推理代码如下</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="s1">&#39;data/body.jpg&#39;</span>
<span class="n">result</span><span class="o">.</span><span class="n">img_with_box</span> <span class="o">=</span> <span class="n">det</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">img</span><span class="p">,</span><span class="n">img_type</span><span class="o">=</span><span class="s1">&#39;cv2&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">result</span></code>保存了检测框四个顶点的坐标，<code class="docutils literal notranslate"><span class="pre">img_with_box</span></code>以cv2格式保存了包含了检测框的图片</p>
<p><code class="docutils literal notranslate"><span class="pre">det.inference()</span></code>可传入参数：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">data</span></code>：指定待检测的图片</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">img_type</span></code>：目标检测完成后会返回含有检测框的图片，该参数指定了返回图片的格式，可选有:<code class="docutils literal notranslate"><span class="pre">['cv2','pil']</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">thr:</span></code> 设置检测框阈值，超过该阈值的检测框被视为有效检测框，进行显示</p></li>
</ul>
</section>
<section id="id19">
<h4>3. 结果输出<a class="headerlink" href="#id19" title="Permalink to this headline"></a></h4>
<p>XEdu-Hub提供了一种便捷的方式，能够以标准美观的格式查看检测框顶点坐标、检测分数以及目标类别，代码如下</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">format_result</span> <span class="o">=</span><span class="n">det</span><span class="o">.</span><span class="n">format_output</span><span class="p">(</span><span class="n">lang</span><span class="o">=</span><span class="s1">&#39;zh&#39;</span><span class="p">)</span><span class="c1"># 参数language设置了输出结果的语言</span>
</pre></div>
</div>
<p>显示带有检测框的图片</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">det</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">img_with_box</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id20">
<h4>4. 结果保存<a class="headerlink" href="#id20" title="Permalink to this headline"></a></h4>
<p>XEdu-Hub提供了带有检测框图片的方法，代码如下</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">det</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">img_with_box</span><span class="p">,</span><span class="s1">&#39;img_with_box.jpg&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="id21">
<h3>目标检测+关键点识别综合应用<a class="headerlink" href="#id21" title="Permalink to this headline"></a></h3>
<p>以下代码可以实时检测摄像头中出现的多个人，并对每一个人体提取关键点。</p>
<p>其中，我们先进行目标检测，拿到所有的检测框<code class="docutils literal notranslate"><span class="pre">bbox</span></code>及其顶点坐标</p>
<p>随后对每个检测框中的人体进行关键点提取。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">cv2</span>
<span class="n">cap</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">pose</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;body17&#39;</span><span class="p">)</span><span class="c1"># 实例化pose模型</span>
<span class="n">det</span> <span class="o">=</span> <span class="n">wf</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;bodydetect&#39;</span><span class="p">)</span><span class="c1">#实例化detect模型</span>
<span class="k">while</span> <span class="n">cap</span><span class="o">.</span><span class="n">isOpened</span><span class="p">():</span>
    <span class="n">ret</span><span class="p">,</span> <span class="n">frame</span> <span class="o">=</span> <span class="n">cap</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">ret</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="n">bboxs</span> <span class="o">=</span> <span class="n">det</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">frame</span><span class="p">,</span><span class="n">threshold</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">frame</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">bboxs</span><span class="p">:</span>
        <span class="n">keypoints</span><span class="p">,</span><span class="n">img</span> <span class="o">=</span><span class="n">pose</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">img</span><span class="p">,</span><span class="n">get_img</span><span class="o">=</span><span class="s1">&#39;cv2&#39;</span><span class="p">,</span><span class="n">bbox</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
    <span class="k">for</span> <span class="p">[</span><span class="n">x1</span><span class="p">,</span><span class="n">y1</span><span class="p">,</span><span class="n">x2</span><span class="p">,</span><span class="n">y2</span><span class="p">]</span> <span class="ow">in</span> <span class="n">bboxs</span><span class="p">:</span> <span class="c1"># 画检测框</span>
        <span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">x1</span><span class="p">),</span><span class="nb">int</span><span class="p">(</span><span class="n">y1</span><span class="p">)),(</span><span class="nb">int</span><span class="p">(</span><span class="n">x2</span><span class="p">),</span><span class="nb">int</span><span class="p">(</span><span class="n">y2</span><span class="p">)),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">255</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s1">&#39;video&#39;</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="mh">0xFF</span> <span class="o">==</span> <span class="nb">ord</span><span class="p">(</span><span class="s1">&#39;q&#39;</span><span class="p">):</span>
        <span class="k">break</span>    
<span class="n">cap</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">destroyAllWindows</span><span class="p">()</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021-2023 OpenXLabEdu.All Rights Reserved.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>